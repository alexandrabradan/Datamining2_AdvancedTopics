{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Data mining project - 2020/21</b><br>\n",
    "<b>Authors</b>: [Alexandra Bradan](https://github.com/alexandrabradan), [Alice Graziani](https://github.com/alicegraziani25) and [Eleonora Cocciu](https://github.com/eleonoracocciu)<br>\n",
    "<b>Python version</b>: 3.x<br>\n",
    "<b>Last update: 21/05/2021<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system library\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import tqdm\n",
    "import ast\n",
    "\n",
    "# useful libraries\n",
    "import math\n",
    "import operator\n",
    "import itertools\n",
    "import statistics\n",
    "import collections\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "from numpy import std\n",
    "from numpy import mean\n",
    "from numpy import percentile\n",
    "\n",
    "# visualisarion\n",
    "import pydotplus\n",
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from IPython.display import Image\n",
    "\n",
    "# sklearn\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# dimensional reducers\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif  # classification\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression  # regression\n",
    "\n",
    "# scalers\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# performance visualisation \n",
    "from sklearn import tree\n",
    "from scikitplot.metrics import plot_roc\n",
    "from scikitplot.metrics import plot_precision_recall\n",
    "from scikitplot.metrics import plot_cumulative_gain\n",
    "from scikitplot.metrics import plot_lift_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from yellowbrick.model_selection import LearningCurve\n",
    "\n",
    "# tree classifiers\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# linear classifiers\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# neighbors classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# naive_bayes classifiers\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# ensemble classifiers\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True\n",
    "%matplotlib inline\n",
    "\n",
    "from yellowbrick.style import set_palette\n",
    "set_palette('bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"MLPClassifier_1_layer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Datasets loading </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92834, 55) (10874, 55)\n",
      "(92834, 1) (10874, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv('../../data/fma_metadata/X_train_merged.csv', index_col=0)\n",
    "X_test = pd.read_csv('../../data/fma_metadata/X_test.csv', index_col=0)\n",
    "\n",
    "y_train = pd.read_csv('../../data/fma_metadata/y_train_merged.csv', index_col=0)\n",
    "y_test = pd.read_csv('../../data/fma_metadata/y_test.csv', index_col=0)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Continous, categorical/ordinal column retrieval</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numeric_columns 37\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = []  # continous variables\n",
    "for column_name in X_train.columns:\n",
    "    if (\"track_genre_top\" not in column_name) and  \\\n",
    "          (\"track_date_created_year\" not in column_name) and \\\n",
    "            (\"track_date_created_season\" not in column_name):\n",
    "                numeric_columns.append(column_name)\n",
    "print(\"numeric_columns\", len(numeric_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categoric_columns 18\n"
     ]
    }
   ],
   "source": [
    "categoric_columns = []  # ordinal or categorical variables\n",
    "for column_name in X_train.columns:\n",
    "    if (\"track_genre_top\" in column_name) or  \\\n",
    "          (\"track_date_created_year\" in column_name) or \\\n",
    "            (\"track_date_created_season\" in column_name):\n",
    "                categoric_columns.append(column_name)\n",
    "print(\"categoric_columns\", len(categoric_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Define current (filtered) train and test</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX_tr = X_train.copy()\\ny_tr = y_train.copy()\\nX_ts = X_test.copy()\\ny_ts = y_test.copy()\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr = X_train[numeric_columns].copy()\n",
    "y_tr = y_train.copy()\n",
    "X_ts = X_test[numeric_columns].copy()\n",
    "y_ts = y_test.copy()\n",
    "\n",
    "\"\"\"\n",
    "X_tr = X_train.copy()\n",
    "y_tr = y_train.copy()\n",
    "X_ts = X_test.copy()\n",
    "y_ts = y_test.copy()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Load the black-box model</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator StandardScaler from version 0.24.0 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.24.0 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.24.0 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "model_info = None\n",
    "model = None\n",
    "with open('pickle/' + model_name + '_numeric.pickle', 'rb') as handle:\n",
    "    model_info = pickle.load(handle)\n",
    "    bb = model_info['tuned_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.001, hidden_layer_sizes=(5,),\n",
       "              learning_rate='invscaling', momentum=0.2, random_state=42,\n",
       "              tol=0.01)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Filter attributes</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_info['model_name'] != 'Plain':\n",
    "    n_features = model_info['params']['rfe__n_features_to_select']\n",
    "    best_features = model_info['best_features']\n",
    "\n",
    "    if n_features == len(best_features):\n",
    "        X_tr = X_tr[best_features].copy()\n",
    "        X_ts = X_ts[best_features].copy()\n",
    "    else:\n",
    "        print(\"Wrong feature filtering\")\n",
    "        sys.exit(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Scale data </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for column_name in X_tr.columns:\n",
    "        scaler = model_info['params']['preprocessor__numeric__scaler']\n",
    "        X_tr[column_name] = scaler.fit_transform(X_tr[column_name].values.reshape(-1,1))[:, 0]\n",
    "        X_ts[column_name] = scaler.transform(X_ts[column_name].values.reshape(-1,1))[:, 0]\n",
    "except KeyError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Train model (again, for certainty)</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.001, hidden_layer_sizes=(5,),\n",
       "              learning_rate='invscaling', momentum=0.2, random_state=42,\n",
       "              tol=0.01)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.fit(X_tr.values, y_tr.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_predict(X):\n",
    "    return bb.predict(X)\n",
    "\n",
    "def bb_predict_proba(X):\n",
    "    return bb.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bb_predict(X_ts.values)\n",
    "y_prob = bb_predict_proba(X_ts.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Local XAIs </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Select correctly predicted records to explain </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2e_list = []\n",
    "for i2e, (y_t, y_p) in enumerate(zip(y_ts.values.ravel(), y_pred)):\n",
    "    if (y_t == y_p) and (y_t == 1):\n",
    "        i2e_list.append(i2e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(i2e_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1080"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in y_ts.values.ravel() if x == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>LIME explanaibility </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Lime Explainer\n",
    "# Be very careful in setting the order of the class names\n",
    "lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    X_tr.values,\n",
    "    training_labels=y_tr.values.ravel(),\n",
    "    feature_names=X_tr.columns.tolist(),\n",
    "    # feature_selection=\"lasso_path\",\n",
    "    class_names=[\"Studio_Recording\", \"Live_Recording\"],\n",
    "    discretize_continuous=True,\n",
    "    #discretizer=\"entropy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 243/243 [1:21:43<00:00, 20.18s/it]\n"
     ]
    }
   ],
   "source": [
    "for i2e in tqdm.tqdm(i2e_list):\n",
    "    x = X_ts.iloc[i2e]\n",
    "    exp = lime_explainer.explain_instance(X_ts.iloc[i2e], bb.predict_proba, num_features=5)\n",
    "    # exp.show_in_notebook(show_table=True)\n",
    "    # exp.as_pyplot_figure()\n",
    "    \n",
    "    # retrieve the features that made possible this outcome\n",
    "    xai = exp.local_exp[1]\n",
    "    xai_features = [X_tr.columns[c] for c, v in xai]\n",
    "    xai_scores = [v for c, v in xai]\n",
    "    \n",
    "    xai_filtered_scores = []\n",
    "    xai_filtered_features = []\n",
    "    for i, score in enumerate(xai_scores):\n",
    "        if score > 0:\n",
    "            xai_filtered_scores.append(score)\n",
    "            xai_filtered_features.append(xai_features[i])\n",
    "\n",
    "    try:\n",
    "        tmp_list = lime_dict[str(xai_filtered_features)] \n",
    "        tmp_list.append({i2e: xai_filtered_scores})\n",
    "        lime_dict[str(xai_filtered_features)] = tmp_list\n",
    "    except KeyError:\n",
    "        lime_dict[str(xai_filtered_features)] = [{i2e: xai_filtered_scores}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many records where classified according to a given feature combination \n",
    "# (without taking into account repetions)\n",
    "lime_dict_counter_with_repetitions = {}\n",
    "for key, value in lime_dict.items():\n",
    "    lime_dict_counter_with_repetitions[key] = len(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lime_dict_counter_with_repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# order alpabetical feature combinations\n",
    "lime_dict_counter_alpabetical_ordered = {}\n",
    "for key, value in lime_dict_counter_with_repetitions.items():\n",
    "    key = sorted(ast.literal_eval(key))  # alpabetical ordered list\n",
    "    try:\n",
    "        lime_dict_counter_alpabetical_ordered[str(key)] += value\n",
    "    except KeyError:\n",
    "        lime_dict_counter_alpabetical_ordered[str(key)] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lime_dict_counter_alpabetical_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# order dict by incrising key length\n",
    "def get_len(key):\n",
    "    return len(key[0])\n",
    "\n",
    "test_dict_list = list(lime_dict_counter_alpabetical_ordered.items())\n",
    "test_dict_list.sort(key = get_len)\n",
    "lime_dict_counter_alpabetical_ordered_incr_length = {ele[0] : ele[1]  for ele in test_dict_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lime_dict_counter_alpabetical_ordered_incr_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most_specific_length=1\n"
     ]
    }
   ],
   "source": [
    "most_specific_length = sys.maxsize\n",
    "for key, value in lime_dict_counter_alpabetical_ordered_incr_length.items():\n",
    "    key_set = set(ast.literal_eval(key))\n",
    "    if len(key_set) < most_specific_length:\n",
    "        most_specific_length = len(key_set)\n",
    "print(\"most_specific_length=%s\" % most_specific_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count how many records where classified according to a given feature combination (without repetions)\n",
    "# and taking into account the most general combinations\n",
    "# N.B. a specific feature combination can have one or more general feature combinations as subset\n",
    "lime_dict_counter = {}\n",
    "accounted_indeces = set()\n",
    "for i, (key, value) in enumerate(lime_dict_counter_alpabetical_ordered_incr_length.items()):\n",
    "    key_set = set(ast.literal_eval(key))\n",
    "    if len(key_set) == most_specific_length:\n",
    "        for i2, (key2, value2) in enumerate(lime_dict_counter_alpabetical_ordered_incr_length.items()):\n",
    "            key2_set = set(ast.literal_eval(key2))\n",
    "            \n",
    "            inters = key_set.intersection(key2_set)\n",
    "            if len(inters) == len(key_set):\n",
    "                try:\n",
    "                    lime_dict_counter[key] += value2\n",
    "                except:\n",
    "                    lime_dict_counter[key] = value2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"['rmse_01']\": 71, \"['mfcc_08']\": 29, \"['spectral_contrast_05']\": 9}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lime_dict_counter_descending_value = \\\n",
    "                    dict(OrderedDict(sorted(lime_dict_counter.items(), \\\n",
    "                                                      key=lambda kv: kv[1], reverse=True)))\n",
    "lime_dict_counter_descending_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_recurrent_and_specific_combination = next(iter(lime_dict_counter_descending_value))\n",
    "most_recurrent_and_specific_combination = set(ast.literal_eval(most_recurrent_and_specific_combination))\n",
    "for i, (key, value) in enumerate(lime_dict.items()):\n",
    "    key = set(sorted(ast.literal_eval(key)))  # alpabetical ordered list\n",
    "    if len(most_recurrent_and_specific_combination.intersection(key)) ==  \\\n",
    "                                            len(most_recurrent_and_specific_combination):\n",
    "        for dict_v in value:\n",
    "            i2e = next(iter(dict_v))\n",
    "            exp = lime_explainer.explain_instance(X_ts.iloc[i2e], bb.predict_proba, num_features=5)\n",
    "            print(i)\n",
    "            exp.show_in_notebook(show_table=True)\n",
    "\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            exp.as_pyplot_figure()\n",
    "            plt.xlabel(\"Predicition probability contribution\")\n",
    "            plt.title(\"Local explanation for class Live_Recording in %s\" % model_name)\n",
    "            plt.show()\n",
    "            print(\"------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_top_5 = ['rmse_01', 'spectral_contrast_07',  'mfcc_04', 'mfcc_02', 'spectral_contrast_05']\n",
    "shap_top_5_set = set(shap_top_5)\n",
    "for i, (key, value) in enumerate(lime_dict.items()):\n",
    "    key = set(ast.literal_eval(key))  \n",
    "    inters = shap_top_5_set.intersection(key)\n",
    "    if len(inters) > 0 :\n",
    "        for v_dict in value:\n",
    "            i2e = next(iter(v_dict))\n",
    "            exp = lime_explainer.explain_instance(X_ts.iloc[i2e], bb.predict_proba, num_features=5)\n",
    "            \n",
    "            print(i)\n",
    "            exp.show_in_notebook(show_table=True)\n",
    "\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            exp.as_pyplot_figure()\n",
    "            plt.xlabel(\"Predicition probability contribution\")\n",
    "            plt.title(\"Local explanation for class Live_Recording in %s\" % model_name)\n",
    "            plt.show()\n",
    "            print(\"------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "shap_top_5 = ['rmse_01', 'spectral_contrast_07',  'mfcc_04', 'mfcc_02', 'spectral_contrast_05']\n",
    "shap_top_5_set = set(shap_top_5)\n",
    "for i, (key, value) in enumerate(lime_dict.items()):\n",
    "    key = set(ast.literal_eval(key))  \n",
    "    inters = shap_top_5_set.intersection(key)\n",
    "    if len(inters) > 0 :\n",
    "        if len(inters) > 0 :\n",
    "            for v_dict in value:\n",
    "                count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{1207: [0.0426144054152482, 0.039580624785416546, 0.03827787304555701]}]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "shap_top_5 = ['rmse_01', 'spectral_contrast_07',  'mfcc_04', 'mfcc_02', 'spectral_contrast_05']\n",
    "shap_top_5_set = set(shap_top_5)\n",
    "for i, (key, value) in enumerate(lime_dict.items()):\n",
    "    key = set(ast.literal_eval(key))  \n",
    "    inters = shap_top_5_set.intersection(key)\n",
    "    if len(inters) > 0 :\n",
    "        if i == 66:\n",
    "            print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{1963: [0.0994936546873854]}, {1965: [0.10001437752938529]}, {4340: [0.09353740177520038]}]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "shap_top_5 = ['rmse_01', 'spectral_contrast_07',  'mfcc_04', 'mfcc_02', 'spectral_contrast_05']\n",
    "shap_top_5_set = set(shap_top_5)\n",
    "for i, (key, value) in enumerate(lime_dict.items()):\n",
    "    key = set(ast.literal_eval(key))  \n",
    "    inters = shap_top_5_set.intersection(key)\n",
    "    if len(inters) > 0 :\n",
    "        if i == 99:\n",
    "            print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22199\n",
      "34312\n"
     ]
    }
   ],
   "source": [
    "indeces = X_ts.index.to_list()\n",
    "print(indeces[1207])\n",
    "print(indeces[1963])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
