{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Data mining project - 2020/21</b><br>\n",
    "<b>Authors</b>: [Alexandra Bradan](https://github.com/alexandrabradan), [Alice Graziani](https://github.com/alicegraziani25) and [Eleonora Cocciu](https://github.com/eleonoracocciu)<br>\n",
    "<b>Python version</b>: 3.x<br>\n",
    "<b>Last update: 21/05/2021<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /home/alexandra/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/alexandra/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/alexandra/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home/alexandra/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/alexandra/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/alexandra/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/alexandra/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/alexandra/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "# system library\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# useful libraries\n",
    "import math\n",
    "import operator\n",
    "import itertools\n",
    "import statistics\n",
    "import collections\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "from numpy import std\n",
    "from numpy import mean\n",
    "from numpy import percentile\n",
    "\n",
    "# visualisarion\n",
    "import pydotplus\n",
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from IPython.display import Image\n",
    "\n",
    "# sklearn\n",
    "import sklearn\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# dimensional reducers\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif  # classification\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression  # regression\n",
    "\n",
    "# scalers\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# performance visualisation \n",
    "from sklearn import tree\n",
    "from scikitplot.metrics import plot_roc\n",
    "from scikitplot.metrics import plot_precision_recall\n",
    "from scikitplot.metrics import plot_cumulative_gain\n",
    "from scikitplot.metrics import plot_lift_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from yellowbrick.model_selection import LearningCurve\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score \n",
    "\n",
    "# tree classifiers\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# linear classifiers\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# neighbors classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# naive_bayes classifiers\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# ensemble classifiers\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# nn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True\n",
    "%matplotlib inline\n",
    "\n",
    "from yellowbrick.style import set_palette\n",
    "set_palette('bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Global parameters </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 10\n",
    "scoring = 'f1_weighted'\n",
    "random_state = 42\n",
    "\n",
    "# test_n_splits = 9\n",
    "test_n_splits = 3\n",
    "\n",
    "model = MLPClassifier(random_state=random_state)\n",
    "model_name = \"MLPClassifier\"\n",
    "\n",
    "learning_curve_flag = False\n",
    "v_or_t_flag = \"TST\"\n",
    "cmap = plt.cm.Greys\n",
    "color = \"grey\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Datasets loading </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92834, 55) (10874, 55)\n",
      "(92834, 1) (10874, 1)\n",
      "(92834, 28) (10874, 28)\n",
      "(92834, 1) (10874, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv('../../data/fma_metadata/X_train_merged.csv', index_col=0)\n",
    "X_test = pd.read_csv('../../data/fma_metadata/X_test.csv', index_col=0)\n",
    "\n",
    "y_train = pd.read_csv('../../data/fma_metadata/y_train_merged.csv', index_col=0)\n",
    "y_test = pd.read_csv('../../data/fma_metadata/y_test.csv', index_col=0)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n",
    "X_train_vt = pd.read_csv('../../data/fma_metadata/X_train_merged_vt.csv', index_col=0)\n",
    "X_test_vt = pd.read_csv('../../data/fma_metadata/X_test_vt.csv', index_col=0)\n",
    "\n",
    "print(X_train_vt.shape, X_test_vt.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Continous, categorical/ordinal column retrieval</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numeric_columns 37\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = []  # continous variables\n",
    "for column_name in X_train.columns:\n",
    "    if (\"track_genre_top\" not in column_name) and  \\\n",
    "          (\"track_date_created_year\" not in column_name) and \\\n",
    "            (\"track_date_created_season\" not in column_name):\n",
    "                numeric_columns.append(column_name)\n",
    "print(\"numeric_columns\", len(numeric_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categoric_columns 18\n"
     ]
    }
   ],
   "source": [
    "categoric_columns = []  # ordinal or categorical variables\n",
    "for column_name in X_train.columns:\n",
    "    if (\"track_genre_top\" in column_name) or  \\\n",
    "          (\"track_date_created_year\" in column_name) or \\\n",
    "            (\"track_date_created_season\" in column_name):\n",
    "                categoric_columns.append(column_name)\n",
    "print(\"categoric_columns\", len(categoric_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numeric_columns_vt 15\n"
     ]
    }
   ],
   "source": [
    "numeric_columns_vt = list(set(numeric_columns).intersection(set(X_train_vt.columns)))\n",
    "print(\"numeric_columns_vt\", len(numeric_columns_vt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categoric_columns_vt 13\n"
     ]
    }
   ],
   "source": [
    "categoric_columns_vt = list(set(categoric_columns).intersection(set(X_train_vt.columns)))\n",
    "print(\"categoric_columns_vt\", len(categoric_columns_vt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ordinal_columns = ['track_date_created_year', 'track_date_created_season']\\nnumeric_columns = ordinal_columns + numeric_columns\\nnumeric_columns_vt = ordinal_columns + numeric_columns_vt\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UPDATE NUMERIC COLUMNS VERSION \n",
    "\"\"\"ordinal_columns = ['track_date_created_year', 'track_date_created_season']\n",
    "numeric_columns = ordinal_columns + numeric_columns\n",
    "numeric_columns_vt = ordinal_columns + numeric_columns_vt\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Define current (filtered) train and test</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92834, 37) (10874, 37) (92834, 15) (10874, 15)\n",
      "(92834, 1) (10874, 1)\n"
     ]
    }
   ],
   "source": [
    "X_tr = X_train[numeric_columns].copy()\n",
    "y_tr = y_train.copy()\n",
    "X_ts = X_test[numeric_columns].copy()\n",
    "y_ts = y_test.copy()\n",
    "\n",
    "X_tr_vt = X_train_vt[numeric_columns_vt].copy()\n",
    "X_ts_vt = X_test_vt[numeric_columns_vt].copy()\n",
    "\n",
    "print(X_tr.shape, X_ts.shape, X_tr_vt.shape, X_ts_vt.shape)\n",
    "print(y_tr.shape, y_ts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>MLPClassifier (baseline classifier)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_baseline_classification(X_tr, y_tr, X_ts, y_ts):\n",
    "    fitted_model = model.fit(X_tr, y_tr.values.ravel())\n",
    "    y_pred = model.predict(X_ts)\n",
    "    \n",
    "    print(confusion_matrix(y_ts, y_pred))\n",
    "    print(classification_report(y_ts, y_pred))\n",
    "    \n",
    "    try:\n",
    "        features_importance = sorted(zip(X_tr.columns, fitted_model.feature_importances_),reverse=True)\n",
    "        # print(features_importance)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        features_importance = sorted(zip(X_tr.columns, fitted_model.coef_),reverse=True)\n",
    "        # print(features_importance)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Tuned MLPClassifier </h2>\n",
    "\n",
    "Like logistic regression, it can quickly learn a linear separation in feature space for two-class classification tasks, although unlike logistic regression, it learns using the **stochastic gradient descent optimization** algorithm and does **not predict calibrated probabilities**.\n",
    "\n",
    "\n",
    "A Perceptron is a **single neuron model** that was a precursor to larger neural networks. It takes a row of data as input and predicts a class label. This is achieved by calculating the weighted sum of the inputs and a bias (set to 1). The **weighted sum of the input** of the model is called the **activation**:\n",
    "\\begin{equation}\n",
    "Activation = Weights * Inputs + Bias\n",
    "\\end{equation}\n",
    "\n",
    "If the activation is above 0.0, the model will output 1.0; otherwise, it will output 0.0:\n",
    "- Predict 1: If Activation > 0.0\n",
    "- Predict 0: If Activation <= 0.0\n",
    "\n",
    "The predictive capability of neural networks comes from the **hierarchical/multilayered structure** of\n",
    "the networks. **The data structure can learn to represent features at different scales or\n",
    "resolutions and combine them into higher-order features**. \n",
    "\n",
    "<h6>Neurons</h6>\n",
    "The building block for neural networks are **artificial neurons**. These are simple computational\n",
    "units that have **weighted input signals** and produce an **output signal** using an **activation function**.\n",
    "\n",
    "<h6>Neuron Weights</h6>\n",
    "The weights on the inputs are very much **like the coefficients used in a regression equation**. Like linear regression, each neuron also has a **bias** which can be thought of as an input that always has the value 1.0 and it too must be weighted. [For example, a neuron may have two inputs in which case it requires three weights.\n",
    "One for each input and one for the bias]\n",
    "\n",
    "N.B. Weights are often initialized to small random values, such as values in the range 0 to 0.3\n",
    "\n",
    "<h6>>Activation</h6>\n",
    "The weighted inputs are summed and passed through an activation function. An activation function is a simple **mapping of summed weighted input to the output of the neuron**. It is called an activation function because **it governs the threshold at which the neuron is activated and the strength of the output signal** [for example\n",
    "0.5, then the neuron would output a value of 1.0, otherwise it would output a 0.0].\n",
    "\n",
    "Traditionally **nonlinear activation functions are used**. This allows the network to combine\n",
    "the inputs in more complex ways and in turn provide a richer capability in the functions they\n",
    "can model:\n",
    "- logistic function / sigmoid function were used that output a value between 0 and 1 with an s-shaped distribution;\n",
    "- hyperbolic tangent function / Tanh that outputs the same distribution over the range -1 to +1'\n",
    "- rectifier activation function has been shown to provide better results.\n",
    "\n",
    "<h6>Networks of Neurons</h6>\n",
    "Neurons are arranged into **networks of neurons**. A row of neurons is called a layer and one\n",
    "network can have multiple **layers**.\n",
    "\n",
    "<h6>Input/visible layers</h6>\n",
    "The bottom layer that takes input from your dataset is called the visible layer. These are not neurons as described above, but simply pass the input value though to the next layer.\n",
    "\n",
    "N.B. Often a neural network is drawn with a visible layer with one neuron per input value or column in your dataset.\n",
    "\n",
    "<h6>Hidden Layers</h6>\n",
    "Layers after the input layer are called hidden layers because they are not directly exposed to\n",
    "the input. The simplest network structure is to have a single neuron in the hidden layer that\n",
    "directly outputs the value (Percepton). Deep learning can refer to having many hidden layers in\n",
    "your neural network.\n",
    "\n",
    "<h6>Output layer</h6>\n",
    "The final hidden layer is called the output layer and it is responsible for **outputting a value\n",
    "or vector of values** that correspond to the format required for the problem. The choice of\n",
    "activation function in the output layer is strongly constrained by the type of problem that you\n",
    "are modeling:\n",
    "- A regression problem may have a single output neuron and the neuron may have no\n",
    "activation function;\n",
    "- A binary classification problem may have a single output neuron and use a sigmoid\n",
    "activation function to output a value between 0 and 1 to represent the probability of\n",
    "predicting a value for the primary class. This can be turned into a crisp class value by\n",
    "using a threshold of 0.5 and snap values less than the threshold to 0 otherwise to 1.\n",
    "\n",
    "<h6>Stochastic Gradient Descent</h6>\n",
    "The classical training algorithm for neural networks is called stochastic\n",
    "gradient descent. This is where **one row of data is exposed to the network at a time as input**.\n",
    "The network processes the input upward activating neurons as it goes to finally produce an\n",
    "output value. This is called a **forward pass on the network**. \n",
    "The output of the network is compared to the expected output and an error is calculated.\n",
    "This error is then propagated back through the network, one layer at a time, and the weights\n",
    "are updated according to the amount that they contributed to the error. This clever bit of math\n",
    "is called the **Back Propagation algorithm**. The process is repeated for all of the examples in\n",
    "your training data. **One round of updating the network for the entire training dataset** is called\n",
    "an **epoch**. A network may be trained for tens, hundreds or many thousands of epochs.\n",
    "\n",
    "<h6>Weight Updates</h6>\n",
    "The weights in the network can be updated from the errors calculated for each training example\n",
    "and this is called **online learning**. It can result in fast but also chaotic changes to the network. Alternatively, the errors can be saved up across all of the training examples and the network can be updated at the end. This is called **batch learning** and is often more stable.\n",
    "\n",
    "Because datasets are so large and because of computational efficiencies, the size of the\n",
    "batch, the **number of examples the network is shown before an update** is often reduced to a\n",
    "small number, such as tens or hundreds of examples. The amount that weights are updated is\n",
    "controlled by a configuration parameter called the **learning rate**. \n",
    "\n",
    "The update equation can be complemented with additional configuration terms that you can set:\n",
    "- **Momentum** is a term that incorporates the properties from the previous weight update\n",
    "to **allow the weights to continue to change in the same direction** even when there is less\n",
    "error being calculated.\n",
    "- **Learning Rate Decay** is used to **decrease the learning rate over epochs** to allow the\n",
    "network to make large changes to the weights at the beginning and smaller fine tuning\n",
    "changes later in the training schedule.\n",
    "\n",
    "<h6> Data processing </h6>\n",
    "Given that the inputs are multiplied by model coefficients, like linear regression and logistic regression, it is good practice to normalize or standardize data prior to using the model.\n",
    "\n",
    "The Perceptron is a linear classification algorithm. This means that it learns a decision boundary that separates two classes using a line (called a hyperplane) in the feature space. As such, it is appropriate for those problems where the classes can be separated well by a line or linear model, referred to as linearly separable.\n",
    "\n",
    "The coefficients of the model are referred to as **input weights and are trained using the stochastic gradient descent** optimization algorithm.\n",
    "\n",
    "Examples from the training dataset are shown to the model one at a time, the model makes a prediction, and error is calculated. The weights of the model are then updated to reduce the errors for the example. This is called the **Perceptron update rule**. This process is repeated for all examples in the training dataset, called an **epoch**. This process of updating the model using examples is then repeated for many epochs.\n",
    "\n",
    "Model weights are updated with a small proportion of the error each batch, and the proportion is controlled by a hyperparameter called the **learning rate**, typically set to a small value. This is to ensure learning does not occur too quickly, resulting in a possibly lower skill model, referred to as premature convergence of the optimization (search) procedure for the model weights.\n",
    "\\begin{equation}\n",
    "weights(t + 1) = weights(t) + learning_rate * (expected_i – predicted_) * input_i\n",
    "\\end{equation}\n",
    "Training is stopped when the error made by the model falls to a low level or no longer improves, or a maximum number of epochs is performed.\n",
    "\n",
    "\n",
    "\n",
    "**Default parameters**:\n",
    "- hidden_layer_sizes=100, \n",
    "- activation='relu', \n",
    "- solver='adam', \n",
    "- alpha=0.0001, \n",
    "- batch_size='auto',\n",
    "- learning_rate='constant', \n",
    "- learning_rate_init=0.001, \n",
    "- power_t=0.5, \n",
    "- max_iter=200, \n",
    "- shuffle=True, \n",
    "- random_state=None, \n",
    "- tol=0.0001, \n",
    "- verbose=False, \n",
    "- warm_start=False, \n",
    "- momentum=0.9, \n",
    "- nesterovs_momentum=True, \n",
    "- early_stopping=False, \n",
    "- validation_fraction=0.1, \n",
    "- beta_1=0.9, \n",
    "- beta_2=0.999, \n",
    "- epsilon=1e-08,\n",
    "- n_iter_no_change=10, \n",
    "- max_fun=15000\n",
    "\n",
    "**Tuned parameters**:\n",
    "- random_state=42\n",
    "- n_jobs=None\n",
    "- hidden_layer_sizes=100, \n",
    "- activation=['identity', 'logistic', 'tanh', 'relu']\n",
    "- learning_rate=['constant', 'invscaling', 'adaptive'] \n",
    "- alpha = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "- tol_ = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "- momentum = list(np.arange(0.1, 1.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_layer(X_tr):\n",
    "    n_features = X_tr.shape[1]\n",
    "    layers = []\n",
    "    for i in range(1, (n_features + 1)):\n",
    "        layer = (i, )\n",
    "        layers.append(layer)\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_second_layer(X_tr):\n",
    "    n_features = X_tr.shape[1]\n",
    "    layers = []\n",
    "    for i in range(1, (n_features + 1)):\n",
    "        for j in range(1, (n_features + 1)):\n",
    "            layer = (i, j)\n",
    "            layers.append(layer)\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_third_layer(X_tr):\n",
    "    n_features = X_tr.shape[1]\n",
    "    layers = []\n",
    "    for i in range(1, (n_features + 1)):\n",
    "        for j in range(1, (n_features + 1)):\n",
    "            for k in range(1, (n_features + 1)):\n",
    "                layer = (i, j, k)\n",
    "                layers.append(layer)\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fourth_layer(X_tr):\n",
    "    n_features = X_tr.shape[1]\n",
    "    layers = []\n",
    "    for i in range(1, (n_features + 1)):\n",
    "        for j in range(1, (n_features + 1)):\n",
    "            for k in range(1, (n_features + 1)):\n",
    "                for l in range(1, (n_features + 1)):\n",
    "                    layer = (i, j, k, l)\n",
    "                    layers.append(layer)\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fifth_layer(X_tr):\n",
    "    n_features = X_tr.shape[1]\n",
    "    layers = []\n",
    "    for i in range(1, (n_features + 1)):\n",
    "        for j in range(1, (n_features + 1)):\n",
    "            for k in range(1, (n_features + 1)):\n",
    "                for l in range(1, (n_features + 1)):\n",
    "                    for m in range(1, (n_features + 1)):\n",
    "                        layer = (i, j, k, l, m)\n",
    "                        layers.append(layer)\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_grid(X_tr):\n",
    "    grid = dict()\n",
    "    n_features = X_tr.shape[1]\n",
    "    grid['model__hidden_layer_sizes'] = get_first_layer(X_tr) + get_second_layer(X_tr) + get_third_layer(X_tr) + \\\n",
    "                                        get_fourth_layer(X_tr) + get_fifth_layer(X_tr)\n",
    "    grid['model__activation'] = ['identity', 'logistic', 'tanh', 'relu']\n",
    "    grid['model__learning_rate'] = ['constant', 'invscaling', 'adaptive']\n",
    "    grid['model__tol'] = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "    grid['model__alpha'] = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "    grid['model__momentum'] =  list(np.arange(0.1, 1.1, 0.1))\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT FUNCTIONS\n",
    "def plot_roc_curve(y_ts, y_prob):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plot_roc(y_ts, y_prob)\n",
    "    plt.title(\"%s\\'s %s ROC curve\" % (model_name, v_or_t_flag.upper()))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_precision_recall_curve(y_ts, y_prob):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plot_precision_recall(y_ts, y_prob)\n",
    "    plt.title(\"%s\\'s %s Precision-Recall curve\" % (model_name, v_or_t_flag.upper()))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_cumulative_gain_curve(y_ts, y_prob):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plot_cumulative_gain(y_ts, y_prob)\n",
    "    plt.title(\"%s\\'s %s Cumulative Gains curve\" % (model_name, v_or_t_flag.upper()))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_lift_curve_curve(y_ts, y_prob):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plot_lift_curve(y_ts, y_prob)\n",
    "    plt.title(\"%s\\'s %s Lift curve\" % (model_name, v_or_t_flag.upper()))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_confusion_matrix(cm, classes, normalize):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(\"%s\\'s %s classification report\" % (model_name, v_or_t_flag.upper()))\n",
    "    # plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    plt.grid(False)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_classification_report(y_ts, y_pred):\n",
    "    model_report = classification_report(y_ts, \n",
    "                                       y_pred,\n",
    "                                       # target_names=['Studio Recording', 'Live Recording'],\n",
    "                                       output_dict=True)\n",
    "    model_r = pd.DataFrame(model_report).iloc[:-1, :].T\n",
    "    sns.heatmap(model_r, annot=True, cmap=cmap, cbar=False)\n",
    "    plt.title(\"%s\\'s %s confusion matrix\" % (model_name, v_or_t_flag.upper()))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_decision_boundary(X_tr, y_tr, scaler, model):\n",
    "    try:\n",
    "        pca = PCA(n_components=2)\n",
    "        best_visualisation_scaler = StandardScaler()\n",
    "        scaled_X_tr = best_visualisation_scaler.fit_transform(X_tr)\n",
    "        X = pca.fit_transform(scaled_X_tr)\n",
    "        # X = pca.fit_transform(X_tr)\n",
    "        y = y_tr.values.ravel()\n",
    "\n",
    "        model.fit(X, y)\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        fig = plot_decision_regions(X=X, y=y, clf=model, legend=2)\n",
    "        plt.xlabel(\"PCA component 1\")\n",
    "        plt.ylabel(\"PCA component 2\")\n",
    "        plt.title(\"%s's %s decision boundary\" % (model_name, v_or_t_flag))\n",
    "        plt.legend(loc='best')\n",
    "        plt.grid(False)\n",
    "        plt.show()\n",
    "    except ValueError:\n",
    "        return\n",
    "\n",
    "def spot_errors(test_label, test_pred):  \n",
    "    spot_errors = []\n",
    "    label_errors = []\n",
    "    for i in range(len(test_label)):\n",
    "        if test_label[i] != test_pred[i]:\n",
    "            spot_errors.append('darkred')\n",
    "            label_errors.append(\"wrong prediction\")\n",
    "        else:\n",
    "            spot_errors.append('darkgray')\n",
    "            label_errors.append(\"correct prediction\")\n",
    "    return spot_errors, label_errors\n",
    "\n",
    "def classification_visualizer(test_set, test_label, test_pred):\n",
    "    test_label = test_label.values\n",
    "    \n",
    "    f, axs = plt.subplots(nrows=1, ncols=3, figsize=(24,8))\n",
    "    errors, label_errors = spot_errors(test_label, test_pred)\n",
    "    labels = [test_label, test_pred, errors]\n",
    "    titles = ['True Labels', 'Predicted Labels', 'Misclassifications']\n",
    "    \n",
    "    for i in range(0, 3):\n",
    "        axs[i].scatter(test_set[missclassif_column_name1], test_set[missclassif_column_name2], c=labels[i], cmap='cividis')\n",
    "        axs[i].set_title(titles[i])\n",
    "        axs[i].set_xlabel(missclassif_column_name1, fontdict={'fontsize': 'large'})\n",
    "        axs[i].set_ylabel(missclassif_column_name2, fontdict={'fontsize': 'large'})\n",
    "        \n",
    "    plt.suptitle('Visualization of the ' + model_name + ' classifier on the %s' % v_or_t_flag)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def error_visualizer(test_set, test_label, test_pred, column_name1, column_name2):\n",
    "    test_label = test_label.values\n",
    "    errors, label_errors = spot_errors(test_label, test_pred)\n",
    "    \n",
    "    palette = ['darkgray', 'darkred']\n",
    "    if errors[0] == 'darkred':\n",
    "        palette = ['darkred', 'darkgray']\n",
    "    \n",
    "    fig = plt.figure(figsize=(5, 6))\n",
    "    sns.scatterplot(x=test_set[column_name1], y=test_set[column_name2], hue=label_errors, palette=palette)\n",
    "    plt.title('%s\\'s %s misclassifications' % (model_name, v_or_t_flag))\n",
    "    plt.xlabel(column_name1)\n",
    "    plt.ylabel(column_name2)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_learning_curve(X_tr, y_tr, model, v_or_t_flag):\n",
    "    second_score = \"\"\n",
    "    if v_or_t_flag == 'VAL':\n",
    "        cv = StratifiedKFold(n_splits=validation_n_splits)\n",
    "        second_score = \"Validation score\"\n",
    "    else:\n",
    "        cv = StratifiedKFold(n_splits=test_n_splits)\n",
    "        second_score = \"Test score\"\n",
    "    sizes = np.linspace(0.3, 1.0, 10)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    visualizer = LearningCurve(model, cv=cv, scoring=scoring, train_sizes=sizes, \n",
    "                                                                        random_state=random_state)\n",
    "\n",
    "    visualizer.fit(X_tr, y_tr.values.ravel())    \n",
    "    # visualizer.ax.get_lines()[1].set_label(second_score)\n",
    "    visualizer.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_features_grid_cv(X_tr, y_tr, results, key):\n",
    "    \n",
    "    if key == 'anova':\n",
    "        best_k = results.best_params_['anova__k']\n",
    "        select_k_best = SelectKBest(score_func=f_classif, k=best_k)\n",
    "        fit = select_k_best.fit(X_tr, y_tr.values.ravel())\n",
    "        df_scores = pd.DataFrame(fit.scores_)\n",
    "        df_columns = pd.DataFrame(X_tr.columns)\n",
    "    elif key == 'rfe':\n",
    "        best_k = results.best_params_['rfe__n_features_to_select']\n",
    "        estimator = results.best_params_['rfe__estimator']\n",
    "        select_rfe = RFE(estimator=estimator, n_features_to_select=best_k)  # best_k=estimator\n",
    "        fit = select_rfe.fit(X_tr, y_tr.values.ravel())\n",
    "        df_scores = pd.DataFrame(fit.ranking_)\n",
    "    else:\n",
    "        print(\"wrong key=%s\" % key)\n",
    "        sys.exit(-1)\n",
    "  \n",
    "    df_columns = pd.DataFrame(X_tr.columns)\n",
    "    feature_scores = pd.concat([df_columns, df_scores],axis=1) # concatenate dataframes\n",
    "    feature_scores.columns = ['features','scores']  # name output columns\n",
    "    feature_scores = feature_scores[feature_scores['scores'] != 0]  # keeping only non-zero scoring features\n",
    "\n",
    "    # plot feature importance\n",
    "    fig = plt.figure(figsize=(8, 10))\n",
    "    # keeping ongly best_k features, ordered in descending score\n",
    "    ordered_k_feature_scores = feature_scores.sort_values('scores', ascending=False).iloc[:best_k]\n",
    "    sns.barplot(y='features', x='scores', data=feature_scores, color=color,\n",
    "                                                            order=ordered_k_feature_scores.features)\n",
    "    plt.grid(False)\n",
    "    plt.title(\"%s's %s feature importance using %s\" % (model_name, v_or_t_flag,  key.upper()))\n",
    "    plt.show()\n",
    "\n",
    "    # retrieve best features \n",
    "    # best_features = [column[0] for column in zip(X_tr.columns, select_k_best.get_support()) if column[1]]\n",
    "    best_features = list(ordered_k_feature_scores.features)\n",
    "    best_features_scores = list(ordered_k_feature_scores.scores)\n",
    "\n",
    "    return best_features, best_features_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importances_or_coef(X_tr, y_tr, tuned_model):\n",
    "\n",
    "    try:\n",
    "        df_scores = pd.DataFrame(tuned_model.feature_importances_)\n",
    "        # best_k = tuned_model.n_features_\n",
    "        best_k =X_tr.shape[0]\n",
    "    except:\n",
    "        try:\n",
    "            df_scores = pd.DataFrame(tuned_model.coef_)\n",
    "\n",
    "            best_k = len([x for x in list(df_scores.values)])\n",
    "        except:\n",
    "            print(\"Wrong curr_model's retrieval feature importance\")\n",
    "            sys.exit(-1)\n",
    "\n",
    "    df_columns = pd.DataFrame(X_tr.columns)   \n",
    "    feature_scores = pd.concat([df_columns, df_scores], axis=1) # concatenate dataframes\n",
    "    feature_scores.columns = ['features','scores']  # name output columns\n",
    "    feature_scores = feature_scores[feature_scores['scores'] != 0]  # keeping only non-zero scoring features\n",
    "\n",
    "    # plot feature importance\n",
    "    fig = plt.figure(figsize=(8, 10))\n",
    "    # keeping ongly best_k features, ordered in descending score\n",
    "    ordered_k_feature_scores = feature_scores.sort_values('scores', ascending=False).iloc[:best_k]\n",
    "    sns.barplot(y='features', x='scores', data=feature_scores, color=color,\n",
    "                                                            order=ordered_k_feature_scores.features)\n",
    "    plt.grid(False)\n",
    "    plt.title(\"%s's %s feature importance\" % (model_name, v_or_t_flag))\n",
    "    plt.show()\n",
    "\n",
    "    # retrieve best features \n",
    "    # best_features = [column[0] for column in zip(X_tr.columns, select_k_best.get_support()) if column[1]]\n",
    "    best_features = list(ordered_k_feature_scores.features)\n",
    "    best_features_scores = list(ordered_k_feature_scores.scores)\n",
    "\n",
    "\n",
    "    return best_features, best_features_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tuned_model(X_tr, y_tr, params):\n",
    "    \n",
    "    X_tr_curr = X_tr.copy()\n",
    "    \n",
    "    model_params = list(model_grid(X_tr_curr).keys())\n",
    "    try:\n",
    "        n_bins = params['preprocessor__numeric__discretizer__n_bins'] \n",
    "        strategy = params['preprocessor__numeric__discretizer__strategy']\n",
    "        encode = params['preprocessor__numeric__discretizer__encode']\n",
    "        discretizer = KBinsDiscretizer(encode=encode, n_bins=n_bins, strategy=strategy)\n",
    "        # scale data\n",
    "        X_tr_curr = discretizer.fit_transform(X_tr_curr.values)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        scaler = params['preprocessor__numeric__discretizer__scaler']\n",
    "        # scale data\n",
    "        X_tr_curr = scaler.fit_transform(X_tr_curr.values)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    # retrieve best hyperameters\n",
    "    tmp_model_hyperparameters = dict((k, params[k]) for k in model_params if k in params)\n",
    "    model_hyperparameters = {}\n",
    "    for key, value in tmp_model_hyperparameters.items():\n",
    "        key = key.split('model__')[1].replace(\"'\", \"\")\n",
    "        model_hyperparameters[key] = value\n",
    "        \n",
    "    tuned_model =  model.set_params(**model_hyperparameters)\n",
    "    tuned_model.fit(X_tr_curr, y_tr.values.ravel())\n",
    "    \n",
    "    plot_decision_boundary(X_tr_curr, y_tr, MinMaxScaler(), tuned_model)  # passing random scaler\n",
    "    \n",
    "    if learning_curve_flag:\n",
    "        plot_learning_curve(X_tr_curr, y_tr, tuned_model, v_or_t_flag)\n",
    "    \n",
    "    return tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(X_tr, y_tr, X_ts, y_ts, numeric_features, categorical_features, discretizer_flag, \n",
    "                                                            scaler_flag, feature_filter_key, feature_flag):\n",
    "    \n",
    "    # define the evaluation method\n",
    "    cv = StratifiedKFold(n_splits=test_n_splits)\n",
    "\n",
    "    # construct the pipeline to evaluate\n",
    "    # scaler = RobustScaler()\n",
    "    grid=model_grid(X_tr)\n",
    "    steps = [('model', model)]\n",
    "        \n",
    "    if feature_filter_key == 'anova':\n",
    "        anova = SelectKBest(score_func=f_classif)\n",
    "        steps.insert(0, ('anova', anova))\n",
    "        grid['anova__k'] = [i+1 for i in range(X_tr.shape[1])]\n",
    "    elif feature_filter_key == 'rfe':\n",
    "        rfe = RFE(estimator=DecisionTreeClassifier())\n",
    "        steps.insert(0, ('rfe', rfe))\n",
    "        grid['rfe__estimator'] = [DecisionTreeClassifier(), LogisticRegression(max_iter=10000)]\n",
    "        grid['rfe__n_features_to_select'] = [i+1 for i in range(X_tr.shape[1])]\n",
    "    \n",
    "    # construct feature type's column transformer\n",
    "    numeric_steps = []\n",
    "    if scaler_flag:      # continous variable normalisation/standardisation\n",
    "        numeric_steps.insert(0, ('scaler', None))\n",
    "        grid['preprocessor__numeric__scaler'] = [MinMaxScaler(), MaxAbsScaler(), StandardScaler(), RobustScaler()]\n",
    "                      \n",
    "    if discretizer_flag:  # continous variable binning\n",
    "        numeric_steps.insert(0, ('discretizer', KBinsDiscretizer(encode='ordinal')))  # ordinal bins\n",
    "        grid['preprocessor__numeric__discretizer__n_bins'] = list(range(2, 11))\n",
    "        grid['preprocessor__numeric__discretizer__strategy'] = ['uniform', 'quantile', 'kmeans']\n",
    "        \n",
    "    numeric_transformer = None\n",
    "    if len(numeric_steps) > 0:\n",
    "        numeric_transformer = Pipeline(steps=numeric_steps)\n",
    "        preprocessor = ColumnTransformer(\n",
    "        transformers=[('numeric', numeric_transformer, numeric_features)])\n",
    "        # add numeric ColumnTransformer to global Pipeline\n",
    "        steps.insert(0, ('preprocessor', preprocessor))\n",
    "        \n",
    "    # define the pipeline to evaluate\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    \n",
    "    # define the grid search\n",
    "    # search = GridSearchCV(pipeline, grid, scoring='f1_weighted',  cv=cv, verbose=1)\n",
    "    search = RandomizedSearchCV(pipeline, grid, scoring=scoring,  \n",
    "                                n_iter=n_iter, cv=cv, verbose=1, refit=scoring, random_state=random_state)\n",
    "    \n",
    "    # perform the search\n",
    "    results = search.fit(X_tr, y_tr.values.ravel())\n",
    "    \n",
    "    # summarize best\n",
    "    score = results.best_score_\n",
    "    params = results.best_params_\n",
    "    print('Best Mean F1_weighted: %.3f ' % score)\n",
    "    print('Best Config: %s ' % params)\n",
    "    \n",
    "    # perform classification (linear model doesn't predict an integer value => no predict_proba)\n",
    "    y_pred = search.predict(X_ts)\n",
    "    y_prob_flag = True\n",
    "    try:\n",
    "        y_prob = search.predict_proba(X_ts)\n",
    "    except:\n",
    "        y_prob = y_pred\n",
    "        y_prob_flag = False\n",
    "    \n",
    "    best_features, best_features_scores = [], []\n",
    "    if feature_filter_key != \"\":\n",
    "        best_features, best_features_scores = get_best_features_grid_cv(X_tr, y_tr, results, feature_filter_key)\n",
    "        X_tr = X_tr[best_features]\n",
    "    \n",
    "    # retrieve the tuned model\n",
    "    tuned_model = get_tuned_model(X_tr, y_tr, params)\n",
    "    if tuned_model !=  pipeline['model']:\n",
    "        print(\"Difference in tuned model and pipeline\")\n",
    "        print(\"tuned_model\", tuned_model)\n",
    "        print(\"pipe\", pipeline['model'])\n",
    "        # print(\"estimator\", results.estimator)\n",
    "        sys.exit(-1)\n",
    "    \n",
    "    # plots\n",
    "    if feature_flag and (feature_filter_key == \"\"):\n",
    "        best_features, best_features_scores = get_feature_importances_or_coef(X_tr, y_tr, tuned_model)\n",
    "    elif (feature_flag) and (feature_filter_key != \"\"):\n",
    "        _ , _ = get_feature_importances_or_coef(X_tr, y_tr, tuned_model)\n",
    " \n",
    "    cm = confusion_matrix(y_ts, y_pred)\n",
    "    plot_confusion_matrix(cm, results.classes_, True)\n",
    "    plot_classification_report(y_ts, y_pred)\n",
    "    \n",
    "    if y_prob_flag:\n",
    "        plot_roc_curve(y_ts, y_prob)\n",
    "        plot_precision_recall_curve(y_ts, y_prob)\n",
    "        plot_cumulative_gain_curve(y_ts, y_prob)\n",
    "        plot_lift_curve_curve(y_ts, y_prob)\n",
    "    else:\n",
    "        print(\"roc\", roc_auc_score(y_ts.values.ravel(), y_pred, average=\"weighted\"))\n",
    "        sklearn.metrics.plot_roc_curve(results, X_ts, y_ts.values.ravel())  \n",
    "        plt.show()\n",
    "    \n",
    "    # plot_decision_boundary(X_tr, y_tr, MinMaxScaler(), tuned_model)  # passing random scaler\n",
    "    # plot_learning_curve(X_tr, y_tr, tuned_model)\n",
    "    # error_visualizer(not_scale_X_ts, y_ts, y_pred, 'chroma_cens_02', 'track_duration')\n",
    "    \n",
    "    return params, tuned_model, y_pred, y_prob, best_features, best_features_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_tst, tuned_model_tst, y_pred_tst, y_prob_tst, best_features, best_features_scores = \\\n",
    "                                                    grid_search(X_tr=X_tr, \n",
    "                                                                y_tr=y_tr,\n",
    "                                                                X_ts=X_ts, \n",
    "                                                                y_ts=y_ts,\n",
    "                                                                numeric_features=numeric_columns, \n",
    "                                                                categorical_features=categoric_columns, \n",
    "                                                                discretizer_flag=False,\n",
    "                                                                scaler_flag=True, \n",
    "                                                                feature_filter_key=\"\", \n",
    "                                                                feature_flag=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\"> <h1> Dimensionality reduction</h1></font>\n",
    "\n",
    "Dimensionality reduction refers to techniques that reduce the number of input variables in a\n",
    "dataset. More input features often make a predictive modeling task more challenging to model,\n",
    "more generally referred to as the **curse of dimensionality**.\n",
    "\n",
    "Dimensionality reduction methods include:\n",
    "- feature selection: use scoring or statistical methods to select which features to keep and which features to delete:\n",
    "    - **Wrapper methods**, wrap a machine learning model, fitting and evaluating the model with different subsets \n",
    "      input features and selecting the subset the results in the best model performance. (i.e. RFE);\n",
    "    - **Filter methods** use scoring methods between the feature and the target variable, to select a\n",
    "      subset of input features that are most predictive (i.e. Pearson’s correlation or Chi-Squared test).\n",
    "- linear algebra methods:\n",
    "    - **Matrix Factorization**: feature matrix (i.e. covariance matrix) can  be ranked and a subset of those parts can       be selected that best captures the salient structure of thematrix that can be used to represent the dataset.       (i.e. PCA);\n",
    "- projection methods / manifold learning and are used to create a low-dimensional projection of high-dimensional data, whilst best preserving the salient structure or relationships in the data (i.e. SOM);\n",
    "- autoencoders: A nueral network model is used that seeks to compress the data flow to a bottleneck layer with far fewer dimensions than the original input data. The part of the model prior to and including the bottleneck is referred to as the encoder, and the part of the model that reads the bottleneck output and reconstructs the input is called the decoder.\n",
    "\n",
    "<u>Typically, linear algebra and manifold learning methods\n",
    "assume that all input features have the same scale or distribution. This suggests that it is\n",
    "good practice to either normalize or standardize data prior to using these methods.</u>\n",
    "\n",
    "<b><font color=\"green\"> \n",
    "For our feature selection process we decided to first use the Pearson Correlation Method to remove highly correlated features (see Features_Data_Understandind.ipynb);\n",
    "Since data dimensionality was still high, we evaluate three different roads:\n",
    "- Univariate Method, using SelectKBest with the ANOVA F-test, since our continous variables are almost alway normal distributed, while our classification target is categorical;\n",
    "- Feature Importance Method, using RFE with features ranked according to feature_importances_ or coef_ derived from a DecisionTreeClassifier() and a LogisticRegression(), respectively;\n",
    "- Variance Threshold, removing features whose variance doesn’t meet a threshold equalt to 0.01\n",
    "</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>ANOVA feature selection (filter method)</h2>\n",
    "\n",
    "<u> Importantly, ANOVA is used when one variable is numeric and one is categorical, such as\n",
    "numerical input variables and a classification target variable in a classification task.</u>\n",
    "\n",
    "ANOVA is an acronym for analysis of variance and is a parametric statistical hypothesis test for\n",
    "determining whether the means from two or more samples of data (often three or more) come\n",
    "from the same distribution or not. An F-statistic, or F-test, is a class of statistical tests that\n",
    "calculate the ratio between variances values, such as the variance from two different samples or\n",
    "the explained and unexplained variance by a statistical test, like ANOVA. The ANOVA method\n",
    "is a type of F-statistic referred to here as an **ANOVA F-test**.\n",
    "\n",
    "\n",
    "The scikit-learn machine library provides an implementation of the ANOVA F-test in the\n",
    "f **classif()** function. This function can be used in a feature selection strategy, such as selecting\n",
    "the top k most relevant features (largest values) via the **SelectKBest** class.\n",
    "\n",
    "\n",
    "We cawilln systematically test a range\n",
    "of different numbers of selected features and discover which results in the best performing\n",
    "model. This is called a grid search, where the k argument to the SelectKBest class can be\n",
    "tuned. It is good practice to evaluate model configurations on classification tasks using repeated\n",
    "stratified k-fold cross-validation. We will use **3-fold cross-validation** via the\n",
    "**StratifiedKFold** class.\n",
    "\n",
    "**Since both class labels are equally important and we assign equl cost to FN and FP, we will use as GridSearch's scoring metric the f1_weighted measure** (we want a trade-off among precision and recall).\n",
    "\n",
    "N.B. \n",
    "- f1_macro => unweighted class label\n",
    "- f1_weighted => weighted class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "anova_params_tst, anova_tuned_model_tst, anova_y_pred_tst, anova_y_prob_tst, \\\n",
    "                anova_best_features, anova_best_features_scores = \\\n",
    "                                                    grid_search(X_tr=X_tr, \n",
    "                                                                y_tr=y_tr,\n",
    "                                                                X_ts=X_ts, \n",
    "                                                                y_ts=y_ts,\n",
    "                                                                numeric_features=numeric_columns, \n",
    "                                                                categorical_features=categoric_columns, \n",
    "                                                                discretizer_flag=False, \n",
    "                                                                scaler_flag=True, \n",
    "                                                                feature_filter_key=\"anova\", \n",
    "                                                                feature_flag=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>RFE (Recursive Feature Elimination) (wrapper method)</h2>\n",
    "\n",
    "The Recursive Feature Elimination (RFE) method works by recursively removing attributes and building a model on those attributes that remain. It uses accuracy metric to rank the feature according to their importance. The RFE method takes the model to be used and the number of required features as input. It then gives the ranking of all the variables, 1 being most important. It also gives its support, True being relevant feature and False being irrelevant feature.\n",
    "\n",
    "RFE **requires a nested algorithm that is used to provide the feature importance scores**, such\n",
    "as a decision tree (**feature_importances_ attribute**) or a linear model(**coef_ attribute**).\n",
    "\n",
    "Feature importance refers to techniques that assign a score to input features based on how\n",
    "useful they are at predicting a target variable:\n",
    "- statistical correlation scores;\n",
    "- coefficients calculated as part of linear models or decision trees;\n",
    "- permutation importance scores.\n",
    "\n",
    "<u> RFECV automatic select best k number of features </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rfe_params_tst, rfe_tuned_model_tst, rfe_y_pred_tst, rfe_y_prob_tst, \\\n",
    "                rfe_best_features, rfe_best_features_scores = \\\n",
    "                                                    grid_search(X_tr=X_tr, \n",
    "                                                                y_tr=y_tr,\n",
    "                                                                X_ts=X_ts, \n",
    "                                                                y_ts=y_ts,\n",
    "                                                                numeric_features=numeric_columns, \n",
    "                                                                categorical_features=categoric_columns, \n",
    "                                                                discretizer_flag=False, \n",
    "                                                                scaler_flag=True, \n",
    "                                                                feature_filter_key=\"rfe\", \n",
    "                                                                feature_flag=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Variance Threshold</h2>\n",
    "\n",
    "Since we have many features, we remove all features whose variance doesn’t meet some threshold. By default, VarianceThreshold removes all zero-variance features, i.e. features that have the same value in all samples.\n",
    "\n",
    "<u>This feature selection algorithm looks only at the features (X), not the desired outputs (y), and can thus be used for unsupervised learning.</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vt_params_tst, vt_tuned_model_tst, vt_y_pred_tst, vt_y_prob_tst, \\\n",
    "                vt_best_features, vt_best_features_scores = \\\n",
    "                                                    grid_search(X_tr=X_tr_vt, \n",
    "                                                                y_tr=y_tr,\n",
    "                                                                X_ts=X_ts_vt, \n",
    "                                                                y_ts=y_ts,\n",
    "                                                                 numeric_features=numeric_columns_vt, \n",
    "                                                                categorical_features=categoric_columns_vt, \n",
    "                                                                discretizer_flag=False, \n",
    "                                                                scaler_flag=True, \n",
    "                                                                feature_filter_key=\"\", \n",
    "                                                                feature_flag=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Test curves </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_multiple_roc_curves(global_info, model_names, v_or_t_flag):\n",
    "    # draw_roc_auc\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    fprs = []\n",
    "    tprs = []\n",
    "    labels = []\n",
    "    for model_name in global_info.keys():\n",
    "        fpr = global_info[str(model_name)][\"fpr\"]\n",
    "        tpr = global_info[str(model_name)][\"tpr\"]\n",
    "        roc_auc = global_info[str(model_name)][\"roc\"] \n",
    "        label = '%s model=%0.4f' % (model_name, roc_auc)\n",
    "        \n",
    "        fprs.append(fpr)\n",
    "        tprs.append(tpr)\n",
    "        labels.append(label)\n",
    "    \n",
    "        # plt.plot(fpr, tpr, label='%s model=%0.4f' % (model_name, roc_auc))\n",
    "        plt.plot(fpr, tpr, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--', color=\"k\", label='No-skilled model=0.5000') \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate') \n",
    "    plt.tick_params(axis='both', which='major')\n",
    "    plt.legend(loc=\"lower right\", title=\"Weighted AUC\", frameon=True)\n",
    "    plt.title(\"%s' %s ROC-curve\" % (model_names, v_or_t_flag))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_curve, roc_auc_score \n",
    "\n",
    "def get_roc_curve_and_roc_auc_score(y_tst, y_prd, curr_model_name, global_info):\n",
    "    fpr, tpr, thresholds = roc_curve(y_tst, y_prd)\n",
    "    roc = roc_auc_score(y_tst, y_prd, average=\"weighted\")\n",
    "    \n",
    "    global_info[str(curr_model_name)][\"fpr\"] = fpr\n",
    "    global_info[str(curr_model_name)][\"tpr\"] = tpr\n",
    "    global_info[str(curr_model_name)][\"roc\"] = roc\n",
    "    \n",
    "    return global_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_info = {}\n",
    "global_info[\"Plain\"] = {}\n",
    "global_info[\"ANOVA\"] = {}\n",
    "global_info[\"RFE\"] = {}\n",
    "global_info[\"VarianceThreshold\"] = {}\n",
    "\n",
    "global_info = get_roc_curve_and_roc_auc_score(y_test.values.ravel(), y_prob_tst[:, 1], \"Plain\", global_info)\n",
    "global_info = get_roc_curve_and_roc_auc_score(y_test.values.ravel(), anova_y_prob_tst[:, 1], \"ANOVA\", global_info)\n",
    "global_info = get_roc_curve_and_roc_auc_score(y_test.values.ravel(), rfe_y_prob_tst[:, 1], \"RFE\", global_info)\n",
    "global_info = get_roc_curve_and_roc_auc_score(y_test.values.ravel(), vt_y_prob_tst[:, 1], \"VarianceThreshold\", global_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_multiple_roc_curves(global_info, model_name + \"s numeric\" , v_or_t_flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Learning curves </h2>\n",
    "\n",
    "This plotting is done at the end of the notebook, beacuse for some reason yellowbrick library overwrite scikitplot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Saving best model on file</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle5 as pickle\n",
    "\n",
    "model_info = {'model_name': 'RFE',\n",
    "              'params': rfe_params_tst,\n",
    "              'tuned_model': rfe_tuned_model_tst,\n",
    "              'y_pred': rfe_y_pred_tst,\n",
    "              'y_prob': rfe_y_prob_tst,\n",
    "              'best_features': rfe_best_features,\n",
    "              'best_features_scores': rfe_best_features_scores\n",
    "             }\n",
    "\n",
    "with open('pickle/' + model_name + '_5_layers_numeric.pickle', 'wb') as handle:\n",
    "    pickle.dump(model_info, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Saving best model on file</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle5 as pickle\n",
    "\n",
    "model_info = {'model_name': 'Plain',\n",
    "              'params': params_tst,\n",
    "              'tuned_model': tuned_model_tst,\n",
    "              'y_pred': y_pred_tst,\n",
    "              'y_prob': y_prob_tst,\n",
    "              'best_features': best_features,\n",
    "              'best_features_scores': best_features_scores\n",
    "             }\n",
    "\n",
    "with open('pickle/' + model_name + '_1_layer_numeric.pickle', 'wb') as handle:\n",
    "    pickle.dump(model_info, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Checking best models among MultiplePerceptron</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier_1_layer_numeric.pickle Plain MLPClassifier_1_layer_numeric\n",
      "MLPClassifier_2_layers_numeric.pickle Plain MLPClassifier_2_layers_numeric\n",
      "MLPClassifier_3_layers_numeric.pickle Plain MLPClassifier_3_layers_numeric\n",
      "MLPClassifier_4_layers_numeric.pickle RFE MLPClassifier_4_layers_numeric\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pickle5 as pickle\n",
    "\n",
    "global_info = {}\n",
    "pickle_dir_files = sorted(os.listdir('pickle/'))\n",
    "for filename in pickle_dir_files:\n",
    "    if 'MLPClassifier' in filename and \"_numeric\" in filename : \n",
    "        with open('pickle/' + filename, 'rb') as handle:\n",
    "            curr_model_info = pickle.load(handle)\n",
    "            \n",
    "            y_prob = curr_model_info['y_prob'] \n",
    "            m = filename.split(\".\")[0]\n",
    "            model_name = curr_model_info['model_name']\n",
    "            model_name = model_name + \" \" + m\n",
    "            \n",
    "            print(filename, model_name)\n",
    "            global_info[model_name] = {}\n",
    "            global_info = get_roc_curve_and_roc_auc_score(y_test.values.ravel(), y_prob[:, 1], \n",
    "                                                                            model_name, global_info)\n",
    "\n",
    "draw_multiple_roc_curves(global_info,  \"MLPClassifiers\", v_or_t_flag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
