{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [FMA: A Dataset For Music Analysis](https://github.com/mdeff/fma)\n",
    "\n",
    "Michaël Defferrard, Kirell Benzi, Pierre Vandergheynst, Xavier Bresson, EPFL LTS2.\n",
    "\n",
    "## Baselines\n",
    "\n",
    "* This notebook evaluates standard classifiers from scikit-learn on the provided features.\n",
    "* Moreover, it evaluates Deep Learning models on both audio and spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import Activation, Dense, Conv1D, Conv2D, MaxPooling1D, Flatten, Reshape\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder, LabelBinarizer, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "#from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "#from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((106574, 52), (106574, 518), (13129, 249))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUDIO_DIR = os.environ.get('AUDIO_DIR')\n",
    "\n",
    "tracks = utils.load('../../data/fma_metadata/tracks.csv')\n",
    "features = utils.load('../../data/fma_metadata/features.csv')\n",
    "echonest = utils.load('../../data/fma_metadata/echonest.csv')\n",
    "\n",
    "np.testing.assert_array_equal(features.index, tracks.index)\n",
    "assert echonest.index.isin(tracks.index).all()\n",
    "\n",
    "tracks.shape, features.shape, echonest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough Echonest features: (13129, 767)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((25000, 52), (25000, 518))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: chance to 'large'\n",
    "subset = tracks.index[tracks['set', 'subset'] <= 'medium']\n",
    "\n",
    "assert subset.isin(tracks.index).all()\n",
    "assert subset.isin(features.index).all()\n",
    "\n",
    "features_all = features.join(echonest, how='inner').sort_index(axis=1)\n",
    "print('Not enough Echonest features: {}'.format(features_all.shape))\n",
    "\n",
    "tracks = tracks.loc[subset]\n",
    "features_all = features.loc[subset]\n",
    "\n",
    "tracks.shape, features_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19922 training examples, 2505 validation examples, 2573 testing examples\n",
      "Top genres (16): ['Blues', 'Classical', 'Country', 'Easy Listening', 'Electronic', 'Experimental', 'Folk', 'Hip-Hop', 'Instrumental', 'International', 'Jazz', 'Old-Time / Historic', 'Pop', 'Rock', 'Soul-RnB', 'Spoken']\n",
      "All genres (151): [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 30, 31, 32, 33, 36, 37, 38, 41, 42, 43, 45, 46, 47, 49, 53, 58, 63, 64, 65, 66, 70, 71, 74, 76, 77, 79, 81, 83, 85, 86, 88, 89, 90, 92, 94, 97, 98, 100, 101, 102, 103, 107, 109, 111, 113, 117, 118, 125, 130, 137, 138, 166, 167, 169, 171, 172, 174, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 214, 224, 232, 236, 240, 247, 250, 267, 286, 296, 297, 311, 314, 322, 337, 359, 360, 361, 362, 374, 378, 400, 401, 404, 428, 439, 440, 441, 442, 443, 456, 468, 491, 495, 502, 504, 514, 524, 538, 539, 542, 580, 602, 619, 651, 659, 695, 741, 763, 808, 810, 811, 906, 1032, 1060, 1193, 1235]\n"
     ]
    }
   ],
   "source": [
    "train = tracks.index[tracks['set', 'split'] == 'training']\n",
    "val = tracks.index[tracks['set', 'split'] == 'validation']\n",
    "test = tracks.index[tracks['set', 'split'] == 'test']\n",
    "\n",
    "print('{} training examples, {} validation examples, {} testing examples'.format(*map(len, [train, val, test])))\n",
    "\n",
    "genres = list(LabelEncoder().fit(tracks['track', 'genre_top']).classes_)\n",
    "#genres = list(tracks['track', 'genre_top'].unique())\n",
    "print('Top genres ({}): {}'.format(len(genres), genres))\n",
    "genres = list(MultiLabelBinarizer().fit(tracks['track', 'genres_all']).classes_)\n",
    "print('All genres ({}): {}'.format(len(genres), genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Multiple classifiers and feature sets\n",
    "\n",
    "Todo:\n",
    "* Cross-validation for hyper-parameters.\n",
    "* Dimensionality reduction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(tracks, features, columns, multi_label=False, verbose=False):\n",
    "    if not multi_label:\n",
    "        # Assign an integer value to each genre.\n",
    "        enc = LabelEncoder()\n",
    "        labels = tracks['track', 'genre_top']\n",
    "        #y = enc.fit_transform(tracks['track', 'genre_top'])\n",
    "    else:\n",
    "        # Create an indicator matrix.\n",
    "        enc = MultiLabelBinarizer()\n",
    "        labels = tracks['track', 'genres_all']\n",
    "        #labels = tracks['track', 'genres']\n",
    "\n",
    "    # Split in training, validation and testing sets.\n",
    "    y_train = enc.fit_transform(labels[train])\n",
    "    y_val = enc.transform(labels[val])\n",
    "    y_test = enc.transform(labels[test])\n",
    "    \"\"\"X_train = features.loc[train, columns].as_matrix()\n",
    "    X_val = features.loc[val, columns].as_matrix()\n",
    "    X_test = features.loc[test, columns].as_matrix()\"\"\"\n",
    "    X_train = features.loc[train, columns].values\n",
    "    X_val = features.loc[val, columns].values\n",
    "    X_test = features.loc[test, columns].values\n",
    "    \n",
    "    \n",
    "    X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "    \n",
    "    # Standardize features by removing the mean and scaling to unit variance.\n",
    "    scaler = StandardScaler(copy=False)\n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.transform(X_val)\n",
    "    scaler.transform(X_test)\n",
    "    \n",
    "    return y_train, y_val, y_test, X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Single genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifiers_features(classifiers, feature_sets, multi_label=False):\n",
    "    columns = list(classifiers.keys()).insert(0, 'dim')\n",
    "    scores = pd.DataFrame(columns=columns, index=feature_sets.keys())\n",
    "    times = pd.DataFrame(columns=classifiers.keys(), index=feature_sets.keys())\n",
    "    for fset_name, fset in tqdm_notebook(feature_sets.items(), desc='features'):\n",
    "        y_train, y_val, y_test, X_train, X_val, X_test = pre_process(tracks, features_all, fset, multi_label)\n",
    "        scores.loc[fset_name, 'dim'] = X_train.shape[1]\n",
    "        for clf_name, clf in classifiers.items():  # tqdm_notebook(classifiers.items(), desc='classifiers', leave=False):\n",
    "            t = time.process_time()\n",
    "            clf.fit(X_train, y_train)\n",
    "            score = clf.score(X_test, y_test)\n",
    "            scores.loc[fset_name, clf_name] = score\n",
    "            times.loc[fset_name, clf_name] = time.process_time() - t\n",
    "    return scores, times\n",
    "\n",
    "def format_scores(scores):\n",
    "    def highlight(s):\n",
    "        is_max = s == max(s[1:])\n",
    "        return ['background-color: yellow' if v else '' for v in is_max]\n",
    "    scores = scores.style.apply(highlight, axis=1)\n",
    "    return scores.format('{:.2%}', subset=pd.IndexSlice[:, scores.columns[1]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-9aaf4f0488ea>:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for fset_name, fset in tqdm_notebook(feature_sets.items(), desc='features'):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1682ad5a594032bc9347bb3f836b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='features', max=18.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/alexandra/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row0_col3 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row1_col3 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row2_col3 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row3_col3 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row4_col10 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row5_col2 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row6_col10 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row7_col3 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row8_col10 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row9_col3 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row10_col10 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row11_col3 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row12_col3 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row13_col3 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row14_col3 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row15_col3 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row16_col3 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row17_col3 {\n",
       "            background-color:  yellow;\n",
       "        }</style><table id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >dim</th>        <th class=\"col_heading level0 col1\" >LR</th>        <th class=\"col_heading level0 col2\" >kNN</th>        <th class=\"col_heading level0 col3\" >SVCrbf</th>        <th class=\"col_heading level0 col4\" >SVCpoly1</th>        <th class=\"col_heading level0 col5\" >linSVC1</th>        <th class=\"col_heading level0 col6\" >linSVC2</th>        <th class=\"col_heading level0 col7\" >DT</th>        <th class=\"col_heading level0 col8\" >RF</th>        <th class=\"col_heading level0 col9\" >AdaBoost</th>        <th class=\"col_heading level0 col10\" >MLP1</th>        <th class=\"col_heading level0 col11\" >MLP2</th>        <th class=\"col_heading level0 col12\" >NB</th>        <th class=\"col_heading level0 col13\" >QDA</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75level0_row0\" class=\"row_heading level0 row0\" >chroma_cens</th>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row0_col0\" class=\"data row0 col0\" >84.000000</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row0_col1\" class=\"data row0 col1\" >39.33%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row0_col2\" class=\"data row0 col2\" >37.50%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row0_col3\" class=\"data row0 col3\" >42.29%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row0_col4\" class=\"data row0 col4\" >38.63%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row0_col5\" class=\"data row0 col5\" >39.29%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row0_col6\" class=\"data row0 col6\" >39.02%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row0_col7\" class=\"data row0 col7\" >35.68%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row0_col8\" class=\"data row0 col8\" >33.77%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row0_col9\" class=\"data row0 col9\" >30.86%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row0_col10\" class=\"data row0 col10\" >39.02%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row0_col11\" class=\"data row0 col11\" >33.77%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row0_col12\" class=\"data row0 col12\" >9.99%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row0_col13\" class=\"data row0 col13\" >24.64%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75level0_row1\" class=\"row_heading level0 row1\" >chroma_cqt</th>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row1_col0\" class=\"data row1 col0\" >84.000000</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row1_col1\" class=\"data row1 col1\" >40.42%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row1_col2\" class=\"data row1 col2\" >40.03%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row1_col3\" class=\"data row1 col3\" >44.27%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row1_col4\" class=\"data row1 col4\" >39.95%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row1_col5\" class=\"data row1 col5\" >41.39%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row1_col6\" class=\"data row1 col6\" >40.46%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row1_col7\" class=\"data row1 col7\" >35.45%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row1_col8\" class=\"data row1 col8\" >36.03%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row1_col9\" class=\"data row1 col9\" >35.72%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row1_col10\" class=\"data row1 col10\" >42.52%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row1_col11\" class=\"data row1 col11\" >35.02%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row1_col12\" class=\"data row1 col12\" >1.55%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row1_col13\" class=\"data row1 col13\" >3.03%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75level0_row2\" class=\"row_heading level0 row2\" >chroma_stft</th>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row2_col0\" class=\"data row2 col0\" >84.000000</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row2_col1\" class=\"data row2 col1\" >44.00%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row2_col2\" class=\"data row2 col2\" >43.92%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row2_col3\" class=\"data row2 col3\" >48.31%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row2_col4\" class=\"data row2 col4\" >43.65%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row2_col5\" class=\"data row2 col5\" >44.35%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row2_col6\" class=\"data row2 col6\" >43.14%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row2_col7\" class=\"data row2 col7\" >39.88%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row2_col8\" class=\"data row2 col8\" >38.71%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row2_col9\" class=\"data row2 col9\" >35.25%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row2_col10\" class=\"data row2 col10\" >46.75%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row2_col11\" class=\"data row2 col11\" >38.83%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row2_col12\" class=\"data row2 col12\" >4.20%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row2_col13\" class=\"data row2 col13\" >5.95%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75level0_row3\" class=\"row_heading level0 row3\" >mfcc</th>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row3_col0\" class=\"data row3 col0\" >140.000000</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row3_col1\" class=\"data row3 col1\" >58.03%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row3_col2\" class=\"data row3 col2\" >54.99%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row3_col3\" class=\"data row3 col3\" >60.98%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row3_col4\" class=\"data row3 col4\" >59.66%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row3_col5\" class=\"data row3 col5\" >59.19%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row3_col6\" class=\"data row3 col6\" >56.94%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row3_col7\" class=\"data row3 col7\" >45.74%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row3_col8\" class=\"data row3 col8\" >44.23%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row3_col9\" class=\"data row3 col9\" >41.31%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row3_col10\" class=\"data row3 col10\" >48.97%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row3_col11\" class=\"data row3 col11\" >52.62%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row3_col12\" class=\"data row3 col12\" >41.86%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row3_col13\" class=\"data row3 col13\" >48.39%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75level0_row4\" class=\"row_heading level0 row4\" >rmse</th>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row4_col0\" class=\"data row4 col0\" >7.000000</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row4_col1\" class=\"data row4 col1\" >36.81%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row4_col2\" class=\"data row4 col2\" >38.52%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row4_col3\" class=\"data row4 col3\" >38.90%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row4_col4\" class=\"data row4 col4\" >37.70%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row4_col5\" class=\"data row4 col5\" >37.54%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row4_col6\" class=\"data row4 col6\" >37.35%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row4_col7\" class=\"data row4 col7\" >38.63%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row4_col8\" class=\"data row4 col8\" >37.66%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row4_col9\" class=\"data row4 col9\" >34.67%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row4_col10\" class=\"data row4 col10\" >39.68%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row4_col11\" class=\"data row4 col11\" >38.44%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row4_col12\" class=\"data row4 col12\" >11.78%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row4_col13\" class=\"data row4 col13\" >15.04%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75level0_row5\" class=\"row_heading level0 row5\" >spectral_bandwidth</th>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row5_col0\" class=\"data row5 col0\" >7.000000</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row5_col1\" class=\"data row5 col1\" >40.61%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row5_col2\" class=\"data row5 col2\" >45.39%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row5_col3\" class=\"data row5 col3\" >44.46%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row5_col4\" class=\"data row5 col4\" >40.38%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row5_col5\" class=\"data row5 col5\" >40.42%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row5_col6\" class=\"data row5 col6\" >40.61%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row5_col7\" class=\"data row5 col7\" >42.91%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row5_col8\" class=\"data row5 col8\" >43.33%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row5_col9\" class=\"data row5 col9\" >37.47%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row5_col10\" class=\"data row5 col10\" >45.28%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row5_col11\" class=\"data row5 col11\" >43.49%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row5_col12\" class=\"data row5 col12\" >36.18%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row5_col13\" class=\"data row5 col13\" >34.16%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75level0_row6\" class=\"row_heading level0 row6\" >spectral_centroid</th>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row6_col0\" class=\"data row6 col0\" >7.000000</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row6_col1\" class=\"data row6 col1\" >42.79%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row6_col2\" class=\"data row6 col2\" >45.36%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row6_col3\" class=\"data row6 col3\" >45.71%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row6_col4\" class=\"data row6 col4\" >42.09%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row6_col5\" class=\"data row6 col5\" >42.09%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row6_col6\" class=\"data row6 col6\" >42.17%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row6_col7\" class=\"data row6 col7\" >42.67%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row6_col8\" class=\"data row6 col8\" >43.84%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row6_col9\" class=\"data row6 col9\" >42.60%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row6_col10\" class=\"data row6 col10\" >47.61%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row6_col11\" class=\"data row6 col11\" >46.60%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row6_col12\" class=\"data row6 col12\" >33.31%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row6_col13\" class=\"data row6 col13\" >36.11%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75level0_row7\" class=\"row_heading level0 row7\" >spectral_contrast</th>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row7_col0\" class=\"data row7 col0\" >49.000000</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row7_col1\" class=\"data row7 col1\" >51.61%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row7_col2\" class=\"data row7 col2\" >49.55%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row7_col3\" class=\"data row7 col3\" >54.45%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row7_col4\" class=\"data row7 col4\" >49.59%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row7_col5\" class=\"data row7 col5\" >51.81%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row7_col6\" class=\"data row7 col6\" >48.97%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row7_col7\" class=\"data row7 col7\" >43.53%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row7_col8\" class=\"data row7 col8\" >43.41%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row7_col9\" class=\"data row7 col9\" >39.53%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row7_col10\" class=\"data row7 col10\" >51.50%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row7_col11\" class=\"data row7 col11\" >44.50%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row7_col12\" class=\"data row7 col12\" >39.41%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row7_col13\" class=\"data row7 col13\" >41.78%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75level0_row8\" class=\"row_heading level0 row8\" >spectral_rolloff</th>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row8_col0\" class=\"data row8 col0\" >7.000000</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row8_col1\" class=\"data row8 col1\" >41.86%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row8_col2\" class=\"data row8 col2\" >46.25%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row8_col3\" class=\"data row8 col3\" >47.53%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row8_col4\" class=\"data row8 col4\" >41.43%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row8_col5\" class=\"data row8 col5\" >41.62%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row8_col6\" class=\"data row8 col6\" >41.51%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row8_col7\" class=\"data row8 col7\" >45.36%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row8_col8\" class=\"data row8 col8\" >45.43%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row8_col9\" class=\"data row8 col9\" >41.66%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row8_col10\" class=\"data row8 col10\" >48.27%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row8_col11\" class=\"data row8 col11\" >48.23%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row8_col12\" class=\"data row8 col12\" >28.49%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row8_col13\" class=\"data row8 col13\" >28.53%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75level0_row9\" class=\"row_heading level0 row9\" >tonnetz</th>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row9_col0\" class=\"data row9 col0\" >42.000000</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row9_col1\" class=\"data row9 col1\" >40.11%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row9_col2\" class=\"data row9 col2\" >37.31%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row9_col3\" class=\"data row9 col3\" >42.25%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row9_col4\" class=\"data row9 col4\" >40.23%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row9_col5\" class=\"data row9 col5\" >40.15%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row9_col6\" class=\"data row9 col6\" >39.45%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row9_col7\" class=\"data row9 col7\" >35.91%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row9_col8\" class=\"data row9 col8\" >35.87%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row9_col9\" class=\"data row9 col9\" >34.16%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row9_col10\" class=\"data row9 col10\" >40.15%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row9_col11\" class=\"data row9 col11\" >32.10%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row9_col12\" class=\"data row9 col12\" >22.31%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row9_col13\" class=\"data row9 col13\" >23.05%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75level0_row10\" class=\"row_heading level0 row10\" >zcr</th>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row10_col0\" class=\"data row10 col0\" >7.000000</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row10_col1\" class=\"data row10 col1\" >43.53%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row10_col2\" class=\"data row10 col2\" >44.73%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row10_col3\" class=\"data row10 col3\" >45.43%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row10_col4\" class=\"data row10 col4\" >42.95%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row10_col5\" class=\"data row10 col5\" >42.71%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row10_col6\" class=\"data row10 col6\" >42.09%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row10_col7\" class=\"data row10 col7\" >43.61%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row10_col8\" class=\"data row10 col8\" >43.49%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row10_col9\" class=\"data row10 col9\" >40.89%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row10_col10\" class=\"data row10 col10\" >46.02%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row10_col11\" class=\"data row10 col11\" >45.67%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row10_col12\" class=\"data row10 col12\" >30.39%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row10_col13\" class=\"data row10 col13\" >32.10%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75level0_row11\" class=\"row_heading level0 row11\" >mfcc/contrast</th>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row11_col0\" class=\"data row11 col0\" >189.000000</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row11_col1\" class=\"data row11 col1\" >59.77%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row11_col2\" class=\"data row11 col2\" >55.31%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row11_col3\" class=\"data row11 col3\" >63.04%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row11_col4\" class=\"data row11 col4\" >61.02%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row11_col5\" class=\"data row11 col5\" >59.58%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row11_col6\" class=\"data row11 col6\" >58.65%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row11_col7\" class=\"data row11 col7\" >47.61%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row11_col8\" class=\"data row11 col8\" >44.46%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row11_col9\" class=\"data row11 col9\" >41.62%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row11_col10\" class=\"data row11 col10\" >51.11%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row11_col11\" class=\"data row11 col11\" >55.07%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row11_col12\" class=\"data row11 col12\" >44.03%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row11_col13\" class=\"data row11 col13\" >51.85%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75level0_row12\" class=\"row_heading level0 row12\" >mfcc/contrast/chroma</th>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row12_col0\" class=\"data row12 col0\" >273.000000</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row12_col1\" class=\"data row12 col1\" >60.36%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row12_col2\" class=\"data row12 col2\" >53.13%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row12_col3\" class=\"data row12 col3\" >62.92%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row12_col4\" class=\"data row12 col4\" >61.48%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row12_col5\" class=\"data row12 col5\" >59.11%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row12_col6\" class=\"data row12 col6\" >59.19%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row12_col7\" class=\"data row12 col7\" >47.57%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row12_col8\" class=\"data row12 col8\" >44.23%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row12_col9\" class=\"data row12 col9\" >41.62%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row12_col10\" class=\"data row12 col10\" >52.51%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row12_col11\" class=\"data row12 col11\" >57.33%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row12_col12\" class=\"data row12 col12\" >39.02%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row12_col13\" class=\"data row12 col13\" >51.34%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75level0_row13\" class=\"row_heading level0 row13\" >mfcc/contrast/centroid</th>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row13_col0\" class=\"data row13 col0\" >196.000000</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row13_col1\" class=\"data row13 col1\" >60.47%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row13_col2\" class=\"data row13 col2\" >55.23%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row13_col3\" class=\"data row13 col3\" >63.39%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row13_col4\" class=\"data row13 col4\" >61.48%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row13_col5\" class=\"data row13 col5\" >60.28%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row13_col6\" class=\"data row13 col6\" >59.23%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row13_col7\" class=\"data row13 col7\" >47.57%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row13_col8\" class=\"data row13 col8\" >45.28%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row13_col9\" class=\"data row13 col9\" >41.62%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row13_col10\" class=\"data row13 col10\" >53.36%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row13_col11\" class=\"data row13 col11\" >55.23%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row13_col12\" class=\"data row13 col12\" >43.76%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row13_col13\" class=\"data row13 col13\" >51.69%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75level0_row14\" class=\"row_heading level0 row14\" >mfcc/contrast/chroma/centroid</th>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row14_col0\" class=\"data row14 col0\" >280.000000</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row14_col1\" class=\"data row14 col1\" >60.09%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row14_col2\" class=\"data row14 col2\" >53.01%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row14_col3\" class=\"data row14 col3\" >63.08%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row14_col4\" class=\"data row14 col4\" >61.29%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row14_col5\" class=\"data row14 col5\" >60.12%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row14_col6\" class=\"data row14 col6\" >59.54%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row14_col7\" class=\"data row14 col7\" >47.57%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row14_col8\" class=\"data row14 col8\" >43.96%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row14_col9\" class=\"data row14 col9\" >41.62%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row14_col10\" class=\"data row14 col10\" >53.67%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row14_col11\" class=\"data row14 col11\" >55.15%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row14_col12\" class=\"data row14 col12\" >38.87%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row14_col13\" class=\"data row14 col13\" >51.34%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75level0_row15\" class=\"row_heading level0 row15\" >mfcc/contrast/chroma/centroid/tonnetz</th>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row15_col0\" class=\"data row15 col0\" >322.000000</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row15_col1\" class=\"data row15 col1\" >60.86%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row15_col2\" class=\"data row15 col2\" >52.62%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row15_col3\" class=\"data row15 col3\" >63.12%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row15_col4\" class=\"data row15 col4\" >62.50%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row15_col5\" class=\"data row15 col5\" >60.20%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row15_col6\" class=\"data row15 col6\" >59.74%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row15_col7\" class=\"data row15 col7\" >47.57%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row15_col8\" class=\"data row15 col8\" >45.01%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row15_col9\" class=\"data row15 col9\" >41.62%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row15_col10\" class=\"data row15 col10\" >53.56%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row15_col11\" class=\"data row15 col11\" >57.40%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row15_col12\" class=\"data row15 col12\" >39.06%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row15_col13\" class=\"data row15 col13\" >50.72%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75level0_row16\" class=\"row_heading level0 row16\" >mfcc/contrast/chroma/centroid/zcr</th>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row16_col0\" class=\"data row16 col0\" >287.000000</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row16_col1\" class=\"data row16 col1\" >60.32%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row16_col2\" class=\"data row16 col2\" >53.01%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row16_col3\" class=\"data row16 col3\" >62.81%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row16_col4\" class=\"data row16 col4\" >61.48%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row16_col5\" class=\"data row16 col5\" >59.77%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row16_col6\" class=\"data row16 col6\" >59.81%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row16_col7\" class=\"data row16 col7\" >47.69%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row16_col8\" class=\"data row16 col8\" >44.89%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row16_col9\" class=\"data row16 col9\" >41.62%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row16_col10\" class=\"data row16 col10\" >53.87%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row16_col11\" class=\"data row16 col11\" >56.43%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row16_col12\" class=\"data row16 col12\" >38.90%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row16_col13\" class=\"data row16 col13\" >51.42%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75level0_row17\" class=\"row_heading level0 row17\" >all_non-echonest</th>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row17_col0\" class=\"data row17 col0\" >518.000000</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row17_col1\" class=\"data row17 col1\" >60.63%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row17_col2\" class=\"data row17 col2\" >51.77%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row17_col3\" class=\"data row17 col3\" >62.88%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row17_col4\" class=\"data row17 col4\" >61.95%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row17_col5\" class=\"data row17 col5\" >59.08%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row17_col6\" class=\"data row17 col6\" >60.36%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row17_col7\" class=\"data row17 col7\" >47.30%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row17_col8\" class=\"data row17 col8\" >42.83%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row17_col9\" class=\"data row17 col9\" >41.62%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row17_col10\" class=\"data row17 col10\" >57.44%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row17_col11\" class=\"data row17 col11\" >55.27%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row17_col12\" class=\"data row17 col12\" >9.91%</td>\n",
       "                        <td id=\"T_0c7f7df0_7440_11eb_91c6_4dd49ecfae75row17_col13\" class=\"data row17 col13\" >19.94%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fbefb1f9b20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >LR</th>        <th class=\"col_heading level0 col1\" >kNN</th>        <th class=\"col_heading level0 col2\" >SVCrbf</th>        <th class=\"col_heading level0 col3\" >SVCpoly1</th>        <th class=\"col_heading level0 col4\" >linSVC1</th>        <th class=\"col_heading level0 col5\" >linSVC2</th>        <th class=\"col_heading level0 col6\" >DT</th>        <th class=\"col_heading level0 col7\" >RF</th>        <th class=\"col_heading level0 col8\" >AdaBoost</th>        <th class=\"col_heading level0 col9\" >MLP1</th>        <th class=\"col_heading level0 col10\" >MLP2</th>        <th class=\"col_heading level0 col11\" >NB</th>        <th class=\"col_heading level0 col12\" >QDA</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75level0_row0\" class=\"row_heading level0 row0\" >chroma_cens</th>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row0_col0\" class=\"data row0 col0\" >30.9132</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row0_col1\" class=\"data row0 col1\" >17.2253</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row0_col2\" class=\"data row0 col2\" >122.2521</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row0_col3\" class=\"data row0 col3\" >98.3577</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row0_col4\" class=\"data row0 col4\" >356.3493</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row0_col5\" class=\"data row0 col5\" >120.8837</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row0_col6\" class=\"data row0 col6\" >1.9305</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row0_col7\" class=\"data row0 col7\" >0.1394</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row0_col8\" class=\"data row0 col8\" >2.6690</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row0_col9\" class=\"data row0 col9\" >862.5054</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row0_col10\" class=\"data row0 col10\" >1004.8167</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row0_col11\" class=\"data row0 col11\" >0.5774</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row0_col12\" class=\"data row0 col12\" >1.5945</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75level0_row1\" class=\"row_heading level0 row1\" >chroma_cqt</th>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row1_col0\" class=\"data row1 col0\" >36.2214</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row1_col1\" class=\"data row1 col1\" >16.8099</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row1_col2\" class=\"data row1 col2\" >102.3743</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row1_col3\" class=\"data row1 col3\" >84.1055</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row1_col4\" class=\"data row1 col4\" >360.5293</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row1_col5\" class=\"data row1 col5\" >123.2852</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row1_col6\" class=\"data row1 col6\" >1.8566</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row1_col7\" class=\"data row1 col7\" >0.1351</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row1_col8\" class=\"data row1 col8\" >2.4843</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row1_col9\" class=\"data row1 col9\" >586.0820</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row1_col10\" class=\"data row1 col10\" >1794.2320</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row1_col11\" class=\"data row1 col11\" >0.5724</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row1_col12\" class=\"data row1 col12\" >1.5806</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75level0_row2\" class=\"row_heading level0 row2\" >chroma_stft</th>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row2_col0\" class=\"data row2 col0\" >39.7824</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row2_col1\" class=\"data row2 col1\" >16.0578</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row2_col2\" class=\"data row2 col2\" >114.0940</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row2_col3\" class=\"data row2 col3\" >111.5952</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row2_col4\" class=\"data row2 col4\" >293.3297</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row2_col5\" class=\"data row2 col5\" >122.9768</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row2_col6\" class=\"data row2 col6\" >1.9062</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row2_col7\" class=\"data row2 col7\" >0.1499</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row2_col8\" class=\"data row2 col8\" >2.8296</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row2_col9\" class=\"data row2 col9\" >860.9273</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row2_col10\" class=\"data row2 col10\" >2501.5443</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row2_col11\" class=\"data row2 col11\" >0.5849</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row2_col12\" class=\"data row2 col12\" >1.7448</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75level0_row3\" class=\"row_heading level0 row3\" >mfcc</th>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row3_col0\" class=\"data row3 col0\" >42.6096</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row3_col1\" class=\"data row3 col1\" >26.9208</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row3_col2\" class=\"data row3 col2\" >123.2165</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row3_col3\" class=\"data row3 col3\" >94.2437</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row3_col4\" class=\"data row3 col4\" >271.5330</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row3_col5\" class=\"data row3 col5\" >126.5641</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row3_col6\" class=\"data row3 col6\" >3.0669</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row3_col7\" class=\"data row3 col7\" >0.1968</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row3_col8\" class=\"data row3 col8\" >5.7884</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row3_col9\" class=\"data row3 col9\" >1276.7341</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row3_col10\" class=\"data row3 col10\" >485.3560</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row3_col11\" class=\"data row3 col11\" >0.8507</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row3_col12\" class=\"data row3 col12\" >3.1074</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75level0_row4\" class=\"row_heading level0 row4\" >rmse</th>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row4_col0\" class=\"data row4 col0\" >33.5017</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row4_col1\" class=\"data row4 col1\" >1.4755</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row4_col2\" class=\"data row4 col2\" >33.7580</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row4_col3\" class=\"data row4 col3\" >15.3207</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row4_col4\" class=\"data row4 col4\" >20.8876</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row4_col5\" class=\"data row4 col5\" >15.5118</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row4_col6\" class=\"data row4 col6\" >0.9480</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row4_col7\" class=\"data row4 col7\" >0.1407</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row4_col8\" class=\"data row4 col8\" >0.3933</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row4_col9\" class=\"data row4 col9\" >502.6248</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row4_col10\" class=\"data row4 col10\" >1100.1734</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row4_col11\" class=\"data row4 col11\" >0.1681</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row4_col12\" class=\"data row4 col12\" >0.2325</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75level0_row5\" class=\"row_heading level0 row5\" >spectral_bandwidth</th>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row5_col0\" class=\"data row5 col0\" >33.5140</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row5_col1\" class=\"data row5 col1\" >1.4037</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row5_col2\" class=\"data row5 col2\" >33.8389</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row5_col3\" class=\"data row5 col3\" >16.3596</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row5_col4\" class=\"data row5 col4\" >26.4365</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row5_col5\" class=\"data row5 col5\" >15.8810</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row5_col6\" class=\"data row5 col6\" >0.8382</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row5_col7\" class=\"data row5 col7\" >0.1514</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row5_col8\" class=\"data row5 col8\" >0.3863</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row5_col9\" class=\"data row5 col9\" >520.3049</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row5_col10\" class=\"data row5 col10\" >1454.6899</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row5_col11\" class=\"data row5 col11\" >0.1693</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row5_col12\" class=\"data row5 col12\" >0.1852</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75level0_row6\" class=\"row_heading level0 row6\" >spectral_centroid</th>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row6_col0\" class=\"data row6 col0\" >32.6743</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row6_col1\" class=\"data row6 col1\" >1.3693</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row6_col2\" class=\"data row6 col2\" >31.8015</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row6_col3\" class=\"data row6 col3\" >20.1745</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row6_col4\" class=\"data row6 col4\" >31.4335</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row6_col5\" class=\"data row6 col5\" >28.4149</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row6_col6\" class=\"data row6 col6\" >0.7237</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row6_col7\" class=\"data row6 col7\" >0.2547</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row6_col8\" class=\"data row6 col8\" >0.6221</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row6_col9\" class=\"data row6 col9\" >793.8667</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row6_col10\" class=\"data row6 col10\" >1277.3554</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row6_col11\" class=\"data row6 col11\" >0.1693</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row6_col12\" class=\"data row6 col12\" >0.1869</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75level0_row7\" class=\"row_heading level0 row7\" >spectral_contrast</th>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row7_col0\" class=\"data row7 col0\" >38.5139</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row7_col1\" class=\"data row7 col1\" >10.0844</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row7_col2\" class=\"data row7 col2\" >58.5659</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row7_col3\" class=\"data row7 col3\" >49.2247</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row7_col4\" class=\"data row7 col4\" >124.3609</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row7_col5\" class=\"data row7 col5\" >64.5724</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row7_col6\" class=\"data row7 col6\" >1.5198</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row7_col7\" class=\"data row7 col7\" >0.1421</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row7_col8\" class=\"data row7 col8\" >1.6793</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row7_col9\" class=\"data row7 col9\" >855.7152</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row7_col10\" class=\"data row7 col10\" >1138.6880</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row7_col11\" class=\"data row7 col11\" >0.4043</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row7_col12\" class=\"data row7 col12\" >0.8540</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75level0_row8\" class=\"row_heading level0 row8\" >spectral_rolloff</th>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row8_col0\" class=\"data row8 col0\" >33.7654</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row8_col1\" class=\"data row8 col1\" >1.4270</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row8_col2\" class=\"data row8 col2\" >33.8351</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row8_col3\" class=\"data row8 col3\" >17.2326</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row8_col4\" class=\"data row8 col4\" >25.7188</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row8_col5\" class=\"data row8 col5\" >20.1369</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row8_col6\" class=\"data row8 col6\" >0.9108</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row8_col7\" class=\"data row8 col7\" >0.1344</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row8_col8\" class=\"data row8 col8\" >0.3600</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row8_col9\" class=\"data row8 col9\" >811.2003</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row8_col10\" class=\"data row8 col10\" >1215.7558</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row8_col11\" class=\"data row8 col11\" >0.2015</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row8_col12\" class=\"data row8 col12\" >0.1988</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75level0_row9\" class=\"row_heading level0 row9\" >tonnetz</th>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row9_col0\" class=\"data row9 col0\" >37.4231</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row9_col1\" class=\"data row9 col1\" >8.1218</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row9_col2\" class=\"data row9 col2\" >70.7718</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row9_col3\" class=\"data row9 col3\" >43.0835</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row9_col4\" class=\"data row9 col4\" >105.2472</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row9_col5\" class=\"data row9 col5\" >77.7829</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row9_col6\" class=\"data row9 col6\" >1.4599</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row9_col7\" class=\"data row9 col7\" >0.1591</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row9_col8\" class=\"data row9 col8\" >1.6772</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row9_col9\" class=\"data row9 col9\" >666.9533</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row9_col10\" class=\"data row9 col10\" >2115.8312</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row9_col11\" class=\"data row9 col11\" >0.3595</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row9_col12\" class=\"data row9 col12\" >0.6855</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75level0_row10\" class=\"row_heading level0 row10\" >zcr</th>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row10_col0\" class=\"data row10 col0\" >32.8985</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row10_col1\" class=\"data row10 col1\" >1.3079</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row10_col2\" class=\"data row10 col2\" >31.1279</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row10_col3\" class=\"data row10 col3\" >17.3419</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row10_col4\" class=\"data row10 col4\" >25.1491</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row10_col5\" class=\"data row10 col5\" >15.0316</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row10_col6\" class=\"data row10 col6\" >0.9217</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row10_col7\" class=\"data row10 col7\" >0.1205</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row10_col8\" class=\"data row10 col8\" >0.3294</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row10_col9\" class=\"data row10 col9\" >615.2642</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row10_col10\" class=\"data row10 col10\" >995.8542</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row10_col11\" class=\"data row10 col11\" >0.1703</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row10_col12\" class=\"data row10 col12\" >0.1872</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75level0_row11\" class=\"row_heading level0 row11\" >mfcc/contrast</th>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row11_col0\" class=\"data row11 col0\" >43.4662</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row11_col1\" class=\"data row11 col1\" >31.4880</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row11_col2\" class=\"data row11 col2\" >144.5180</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row11_col3\" class=\"data row11 col3\" >118.6802</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row11_col4\" class=\"data row11 col4\" >364.6083</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row11_col5\" class=\"data row11 col5\" >126.4305</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row11_col6\" class=\"data row11 col6\" >3.7034</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row11_col7\" class=\"data row11 col7\" >0.1656</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row11_col8\" class=\"data row11 col8\" >6.7763</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row11_col9\" class=\"data row11 col9\" >809.0678</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row11_col10\" class=\"data row11 col10\" >357.8676</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row11_col11\" class=\"data row11 col11\" >0.9329</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row11_col12\" class=\"data row11 col12\" >4.3401</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75level0_row12\" class=\"row_heading level0 row12\" >mfcc/contrast/chroma</th>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row12_col0\" class=\"data row12 col0\" >55.2784</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row12_col1\" class=\"data row12 col1\" >42.4838</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row12_col2\" class=\"data row12 col2\" >214.1366</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row12_col3\" class=\"data row12 col3\" >161.5901</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row12_col4\" class=\"data row12 col4\" >502.8428</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row12_col5\" class=\"data row12 col5\" >113.4052</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row12_col6\" class=\"data row12 col6\" >3.6752</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row12_col7\" class=\"data row12 col7\" >0.1303</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row12_col8\" class=\"data row12 col8\" >7.3050</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row12_col9\" class=\"data row12 col9\" >481.1574</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row12_col10\" class=\"data row12 col10\" >463.8314</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row12_col11\" class=\"data row12 col11\" >0.9718</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row12_col12\" class=\"data row12 col12\" >8.1019</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75level0_row13\" class=\"row_heading level0 row13\" >mfcc/contrast/centroid</th>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row13_col0\" class=\"data row13 col0\" >45.2981</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row13_col1\" class=\"data row13 col1\" >24.9175</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row13_col2\" class=\"data row13 col2\" >118.1816</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row13_col3\" class=\"data row13 col3\" >92.0718</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row13_col4\" class=\"data row13 col4\" >301.2394</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row13_col5\" class=\"data row13 col5\" >96.7341</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row13_col6\" class=\"data row13 col6\" >3.1772</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row13_col7\" class=\"data row13 col7\" >0.1291</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row13_col8\" class=\"data row13 col8\" >5.6515</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row13_col9\" class=\"data row13 col9\" >943.2446</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row13_col10\" class=\"data row13 col10\" >487.9206</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row13_col11\" class=\"data row13 col11\" >0.7801</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row13_col12\" class=\"data row13 col12\" >4.8344</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75level0_row14\" class=\"row_heading level0 row14\" >mfcc/contrast/chroma/centroid</th>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row14_col0\" class=\"data row14 col0\" >55.7908</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row14_col1\" class=\"data row14 col1\" >31.2000</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row14_col2\" class=\"data row14 col2\" >161.8032</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row14_col3\" class=\"data row14 col3\" >124.4561</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row14_col4\" class=\"data row14 col4\" >444.2597</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row14_col5\" class=\"data row14 col5\" >111.4696</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row14_col6\" class=\"data row14 col6\" >3.7196</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row14_col7\" class=\"data row14 col7\" >0.1233</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row14_col8\" class=\"data row14 col8\" >7.4363</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row14_col9\" class=\"data row14 col9\" >487.5373</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row14_col10\" class=\"data row14 col10\" >304.0049</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row14_col11\" class=\"data row14 col11\" >1.0246</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row14_col12\" class=\"data row14 col12\" >7.0210</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75level0_row15\" class=\"row_heading level0 row15\" >mfcc/contrast/chroma/centroid/tonnetz</th>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row15_col0\" class=\"data row15 col0\" >59.0915</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row15_col1\" class=\"data row15 col1\" >36.1648</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row15_col2\" class=\"data row15 col2\" >185.0517</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row15_col3\" class=\"data row15 col3\" >140.6601</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row15_col4\" class=\"data row15 col4\" >508.9144</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row15_col5\" class=\"data row15 col5\" >178.9913</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row15_col6\" class=\"data row15 col6\" >6.3901</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row15_col7\" class=\"data row15 col7\" >0.1877</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row15_col8\" class=\"data row15 col8\" >12.7188</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row15_col9\" class=\"data row15 col9\" >616.4203</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row15_col10\" class=\"data row15 col10\" >605.7830</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row15_col11\" class=\"data row15 col11\" >0.9481</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row15_col12\" class=\"data row15 col12\" >10.0398</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75level0_row16\" class=\"row_heading level0 row16\" >mfcc/contrast/chroma/centroid/zcr</th>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row16_col0\" class=\"data row16 col0\" >69.5875</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row16_col1\" class=\"data row16 col1\" >36.0729</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row16_col2\" class=\"data row16 col2\" >187.0637</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row16_col3\" class=\"data row16 col3\" >130.3813</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row16_col4\" class=\"data row16 col4\" >469.9243</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row16_col5\" class=\"data row16 col5\" >118.4851</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row16_col6\" class=\"data row16 col6\" >4.0321</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row16_col7\" class=\"data row16 col7\" >0.1296</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row16_col8\" class=\"data row16 col8\" >8.1279</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row16_col9\" class=\"data row16 col9\" >532.7030</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row16_col10\" class=\"data row16 col10\" >378.1905</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row16_col11\" class=\"data row16 col11\" >1.0394</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row16_col12\" class=\"data row16 col12\" >7.3904</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75level0_row17\" class=\"row_heading level0 row17\" >all_non-echonest</th>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row17_col0\" class=\"data row17 col0\" >72.1917</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row17_col1\" class=\"data row17 col1\" >53.4993</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row17_col2\" class=\"data row17 col2\" >279.9951</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row17_col3\" class=\"data row17 col3\" >220.8503</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row17_col4\" class=\"data row17 col4\" >749.8777</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row17_col5\" class=\"data row17 col5\" >180.9816</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row17_col6\" class=\"data row17 col6\" >6.2410</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row17_col7\" class=\"data row17 col7\" >0.1332</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row17_col8\" class=\"data row17 col8\" >13.3917</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row17_col9\" class=\"data row17 col9\" >363.4688</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row17_col10\" class=\"data row17 col10\" >381.6983</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row17_col11\" class=\"data row17 col11\" >1.2504</td>\n",
       "                        <td id=\"T_0c827bea_7440_11eb_91c6_4dd49ecfae75row17_col12\" class=\"data row17 col12\" >17.8500</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fbefb1af880>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifiers = {\n",
    "    'LR': LogisticRegression(),\n",
    "    'kNN': KNeighborsClassifier(n_neighbors=200),\n",
    "    'SVCrbf': SVC(kernel='rbf'),\n",
    "    'SVCpoly1': SVC(kernel='poly', degree=1),\n",
    "    'linSVC1': SVC(kernel=\"linear\"),\n",
    "    'linSVC2': LinearSVC(),\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
    "    'DT': DecisionTreeClassifier(max_depth=5),\n",
    "    'RF': RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=10),\n",
    "    'MLP1': MLPClassifier(hidden_layer_sizes=(100,), max_iter=2000),\n",
    "    'MLP2': MLPClassifier(hidden_layer_sizes=(200, 50), max_iter=2000),\n",
    "    'NB': GaussianNB(),\n",
    "    'QDA': QuadraticDiscriminantAnalysis(),\n",
    "}\n",
    "\n",
    "feature_sets = {\n",
    "#    'echonest_audio': ('echonest', 'audio_features'),\n",
    "#    'echonest_social': ('echonest', 'social_features'),\n",
    "#    'echonest_temporal': ('echonest', 'temporal_features'),\n",
    "#    'echonest_audio/social': ('echonest', ('audio_features', 'social_features')),\n",
    "#    'echonest_all': ('echonest', ('audio_features', 'social_features', 'temporal_features')),\n",
    "}\n",
    "for name in features.columns.levels[0]:\n",
    "    feature_sets[name] = name\n",
    "feature_sets.update({\n",
    "    'mfcc/contrast': ['mfcc', 'spectral_contrast'],\n",
    "    'mfcc/contrast/chroma': ['mfcc', 'spectral_contrast', 'chroma_cens'],\n",
    "    'mfcc/contrast/centroid': ['mfcc', 'spectral_contrast', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid/tonnetz': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'tonnetz'],\n",
    "    'mfcc/contrast/chroma/centroid/zcr': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'zcr'],\n",
    "    'all_non-echonest': list(features.columns.levels[0])\n",
    "})\n",
    "\n",
    "scores, times = test_classifiers_features(classifiers, feature_sets)\n",
    "\n",
    "ipd.display(format_scores(scores))\n",
    "ipd.display(times.style.format('{:.4f}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Multiple genres\n",
    "\n",
    "Todo:\n",
    "* Ignore rare genres? Count them higher up in the genre tree? On the other hand it's not much tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    #LogisticRegression(),\n",
    "    'LR': OneVsRestClassifier(LogisticRegression()),\n",
    "    'SVC': OneVsRestClassifier(SVC()),\n",
    "    'MLP': MLPClassifier(max_iter=700),\n",
    "}\n",
    "\n",
    "feature_sets = {\n",
    "#    'echonest_audio': ('echonest', 'audio_features'),\n",
    "#    'echonest_temporal': ('echonest', 'temporal_features'),\n",
    "    'mfcc': 'mfcc',\n",
    "    'mfcc/contrast/chroma/centroid/tonnetz': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'tonnetz'],\n",
    "    'mfcc/contrast/chroma/centroid/zcr': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'zcr'],\n",
    "}\n",
    "\n",
    "scores, times = test_classifiers_features(classifiers, feature_sets, multi_label=True)\n",
    "\n",
    "ipd.display(format_scores(scores))\n",
    "ipd.display(times.style.format('{:.4f}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Deep learning on raw audio\n",
    "\n",
    "Other architectures:\n",
    "* [Learning Features of Music from Scratch (MusicNet)](https://arxiv.org/abs/1611.09827), John Thickstun, Zaid Harchaoui, Sham Kakade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_onehot = LabelBinarizer().fit_transform(tracks['track', 'genre_top'])\n",
    "labels_onehot = pd.DataFrame(labels_onehot, index=tracks.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load audio samples in parallel using `multiprocessing` so as to maximize CPU usage when decoding MP3s and making some optional pre-processing. There are multiple ways to load a waveform from a compressed MP3:\n",
    "* librosa uses audioread in the backend which can use many native libraries, e.g. ffmpeg\n",
    "    * resampling is very slow --> use `kaiser_fast`\n",
    "    * does not work with multi-processing, for keras `fit_generator()`\n",
    "* pydub is a high-level interface for audio modification, uses ffmpeg to load\n",
    "    * store a temporary `.wav`\n",
    "* directly pipe ffmpeg output\n",
    "    * fastest method\n",
    "* [pyAV](https://github.com/mikeboers/PyAV) may be a fastest alternative by linking to ffmpeg libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just be sure that everything is fine. Multiprocessing is tricky to debug.\n",
    "utils.FfmpegLoader().load(utils.get_audio_path(AUDIO_DIR, 2))\n",
    "SampleLoader = utils.build_sample_loader(AUDIO_DIR, labels_onehot, utils.FfmpegLoader())\n",
    "SampleLoader(train, batch_size=2).__next__()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras parameters.\n",
    "NB_WORKER = len(os.sched_getaffinity(0))  # number of usables CPUs\n",
    "params = {'pickle_safe': True, 'nb_worker': NB_WORKER, 'max_q_size': 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Fully connected neural network\n",
    "\n",
    "* Two layers with 10 hiddens is no better than random, ~11%.\n",
    "\n",
    "Optimize data loading to be CPU / GPU bound, not IO bound. Larger batches means reduced training time, so increase batch time until memory exhaustion. Number of workers and queue size have no influence on speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = utils.FfmpegLoader(sampling_rate=2000)\n",
    "SampleLoader = utils.build_sample_loader(AUDIO_DIR, labels_onehot, loader)\n",
    "print('Dimensionality: {}'.format(loader.shape))\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Dense(output_dim=1000, input_shape=loader.shape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(output_dim=100))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(output_dim=labels_onehot.shape[1]))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=0.1, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(SampleLoader(train, batch_size=64), train.size, nb_epoch=2, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(val, batch_size=64), val.size, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(test, batch_size=64), test.size, **params)\n",
    "#Y = model.predict_generator(SampleLoader(test, batch_size=64), test.size, **params);\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Convolutional neural network\n",
    "\n",
    "* Architecture: [End-to-end learning for music audio](http://www.mirlab.org/conference_papers/International_Conference/ICASSP%202014/papers/p7014-dieleman.pdf), Sander Dieleman, Benjamin Schrauwen.\n",
    "* Missing: track segmentation and class averaging (majority voting)\n",
    "* Compared with log-scaled mel-spectrograms instead of strided convolution as first layer.\n",
    "* Larger net: http://benanne.github.io/2014/08/05/spotify-cnns.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = utils.FfmpegLoader(sampling_rate=16000)\n",
    "#loader = utils.LibrosaLoader(sampling_rate=16000)\n",
    "SampleLoader = utils.build_sample_loader(AUDIO_DIR, labels_onehot, loader)\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Reshape((-1, 1), input_shape=loader.shape))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv1D(128, 512, subsample_length=512))\n",
    "print(model.output_shape)\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv1D(32, 8))\n",
    "print(model.output_shape)\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling1D(4))\n",
    "\n",
    "model.add(Conv1D(32, 8))\n",
    "print(model.output_shape)\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling1D(4))\n",
    "\n",
    "print(model.output_shape)\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "print(model.output_shape)\n",
    "model.add(Dense(100))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "model.add(Dense(labels_onehot.shape[1]))\n",
    "model.add(Activation(\"softmax\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "#optimizer = keras.optimizers.Adam()#lr=1e-5)#, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(SampleLoader(train, batch_size=10), train.size, nb_epoch=20, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(val, batch_size=10), val.size, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(test, batch_size=10), test.size, **params)\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Recurrent neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Deep learning on extracted audio features\n",
    "\n",
    "Look at:\n",
    "* Pre-processing in Keras: https://github.com/keunwoochoi/kapre\n",
    "* Convolutional Recurrent Neural Networks for Music Classification: https://github.com/keunwoochoi/icassp_2017\n",
    "* Music Auto-Tagger: https://github.com/keunwoochoi/music-auto_tagging-keras\n",
    "* Pre-processor: https://github.com/bmcfee/pumpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 ConvNet on MFCC\n",
    "\n",
    "* Architecture: [Automatic Musical Pattern Feature Extraction Using Convolutional Neural Network](http://www.iaeng.org/publication/IMECS2010/IMECS2010_pp546-550.pdf), Tom LH. Li, Antoni B. Chan and Andy HW. Chun\n",
    "* Missing: track segmentation and majority voting.\n",
    "* Best seen: 17.6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MfccLoader(utils.Loader):\n",
    "    raw_loader = utils.FfmpegLoader(sampling_rate=22050)\n",
    "    #shape = (13, 190)  # For segmented tracks.\n",
    "    shape = (13, 2582)\n",
    "    def load(self, filename):\n",
    "        import librosa\n",
    "        x = self.raw_loader.load(filename)\n",
    "        # Each MFCC frame spans 23ms on the audio signal with 50% overlap with the adjacent frames.\n",
    "        mfcc = librosa.feature.mfcc(x, sr=22050, n_mfcc=13, n_fft=512, hop_length=256)\n",
    "        return mfcc\n",
    "\n",
    "loader = MfccLoader()\n",
    "SampleLoader = utils.build_sample_loader(AUDIO_DIR, labels_onehot, loader)\n",
    "loader.load(utils.get_audio_path(AUDIO_DIR, 2))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Reshape((*loader.shape, 1),  input_shape=loader.shape))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv2D(3, 13, 10, subsample=(1, 4)))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv2D(15, 1, 10, subsample=(1, 4)))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv2D(65, 1, 10, subsample=(1, 4)))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Flatten())\n",
    "print(model.output_shape)\n",
    "model.add(Dense(labels_onehot.shape[1]))\n",
    "model.add(Activation(\"softmax\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "optimizer = keras.optimizers.SGD(1e-3)#lr=0.01, momentum=0.9, nesterov=True)\n",
    "#optimizer = keras.optimizers.Adam()#lr=1e-5)#\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(SampleLoader(train, batch_size=16), train.size, nb_epoch=20, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(val, batch_size=16), val.size, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(test, batch_size=16), test.size, **params)\n",
    "#Y = model.predict_generator(loader, test.size, pickle_safe=True, nb_worker=NB_WORKER, max_q_size=5)\n",
    "\n",
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
